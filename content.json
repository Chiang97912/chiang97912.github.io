{"meta":{"title":"Peter's Blog","subtitle":null,"description":"Stay hungry, stay foolish!","author":"Peter Chiang","url":"http://chiang97912.github.io","root":"/"},"pages":[{"title":"分类","date":"2017-08-20T06:56:53.000Z","updated":"2020-08-01T03:20:40.000Z","comments":false,"path":"categories/index.html","permalink":"http://chiang97912.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-08-25T10:29:35.000Z","updated":"2020-08-01T03:20:40.000Z","comments":true,"path":"tags/index.html","permalink":"http://chiang97912.github.io/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-08-25T10:34:44.000Z","updated":"2025-12-13T12:29:09.992Z","comments":true,"path":"about/index.html","permalink":"http://chiang97912.github.io/about/index.html","excerpt":"","text":"简介 主业是算法工程师，每天和 NLP、大模型 “斗智斗勇”，致力于让 AI 更懂人类语言；副业是读书爱好者、旅行打卡选手、野生摄影师。既能写得动复杂代码，也能扛得动相机走四方，还能在书本里蹲一下午。博客主打一个 “技术硬核 + 生活柔软”，欢迎来我的小天地一起唠技术、聊生活！ 联系方式 E-Mail: chiang97912@gmail.com Github: https://github.com/Chiang97912"}],"posts":[{"title":"机器学习模型评估方法及代码实现","slug":"机器学习模型评估方法及代码实现","date":"2020-01-09T16:04:46.000Z","updated":"2025-12-13T12:19:22.972Z","comments":true,"path":"2020/01/10/机器学习模型评估方法及代码实现/","permalink":"http://chiang97912.github.io/2020/01/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/","excerpt":"混淆矩阵","text":"混淆矩阵 混淆矩阵（confusion matrix）如下所示： 真实\\预测 正例 反例 正例 TP(真正例) FN(假反例) 反例 FP(假正例) TN(真反例) TP: 将正例预测为正例（预测正确）； FN: 将正例预测为负例（预测错误）； FP: 将负例预测为正例（预测错误）； TN: 将负例预测为负例（预测正确）。 正例包括 TP、FN；反例包括 TN、FP 准确率（Accuracy） 定义：指的是分类正确的样本数量占样本总数的比例 公式： $$ A=\\frac{TP+TN}{TP+TN+FN+FP} $$ scikit-learn接口： 12345import numpy as npfrom sklearn.metrics import accuracy_scorey_pred = [0, 2, 1, 3]y_true = [0, 1, 2, 3]accuracy_score(y_true, y_pred) 精确率(Precision) 定义：精确率(Precision)，即查准率。通常我们所说的精确率是正例的精确率，它是被判定为正例的样本中，真正的正例样本的比例。我们同样可以计算负例的精确率，但是通常没有人这样做。精确率主要用来评测是否误检。举个例子，假设一个班级有10个学生，5男5女。我们目标是寻找班级中的女生，返回6个结果分别是男 、 女 、女 、 男 、女 、 男。如果返回的结果中只有3个正确，那么查准率为3/6=0.5。 公式（分类任务）： $$ P=\\frac{TP}{TP+FP}或\\frac{TN}{TN+FN} $$ 在信息检索领域，精确率是返回结果中相关文档的数目与返回结果的数目的比例： $$ precision=\\frac{|{relevant\\ documents}∩{retrieved\\ documents}|}{{retrieved\\ documents}} $$ scikit-learn接口： 12345678910from sklearn.metrics import precision_scorey_true = [0, 1, 2, 0, 1, 2]y_pred = [0, 2, 1, 0, 0, 1]precision_score(y_true, y_pred, average=&#x27;macro&#x27;)precision_score(y_true, y_pred, average=&#x27;micro&#x27;)precision_score(y_true, y_pred, average=&#x27;weighted&#x27;)precision_score(y_true, y_pred, average=None) 注释： macro 度量：对于n个二分类混淆矩阵，在各混淆矩阵上分别计算精确率和召回率，记（P1,R1），（P2,R2）…（Pn，Rn），再计算平均值，得到宏精确率（macro-P）、宏召回率（macro-R），继而得到宏F1（macro-F1）。 micro度量：对于n个二分类混淆矩阵，先对TP、FN、FP、TN求平均值，再用均值计算得到微精确率（micro-P）、微召回率（micro-P），继而得到微F1（micro-F1）。 召回率(Recall) 定义：召回率(Recall)，即查全率。通常我们所说的召回率是正例的召回率，它是被正确分类的正例样本，占所有正例样本的比例。我们同样可以计算负例的召回率，但是通常没有人这样做。召回率主要用来评测是否漏检。举个例子，假设一个班级有10个学生，5男5女。我们目标是寻找班级中的女生，返回6个结果分别是男 、 女 、女 、 男 、女 、 男。总共有5个女生，返回结果中有3个女生，那么查全率为3/5=0.6。 公式（分类任务）： $$ R=\\frac{TP}{TP+FN}或\\frac{TN}{TN+FP} $$ 在信息检索领域，召回率是返回结果中相关文档的数目与所有相关文档的数目的比例： $$ precision=\\frac{|{relevant\\ documents}∩{retrieved\\ documents}|}{{relevant\\ documents}} $$ scikit-learn接口： 12345678910from sklearn.metrics import recall_scorey_true = [0, 1, 2, 0, 1, 2]y_pred = [0, 2, 1, 0, 0, 1]recall_score(y_true, y_pred, average=&#x27;macro&#x27;)recall_score(y_true, y_pred, average=&#x27;micro&#x27;)recall_score(y_true, y_pred, average=&#x27;weighted&#x27;)recall_score(y_true, y_pred, average=None) F1_score 定义：精确率和召回率的调和平均值。 公式： $$ \\frac{1}{F1}=\\frac{1}{2}.(\\frac{1}{P}+\\frac{1}{R})，即F1=\\frac{2\\times P\\times R}{P+R}=\\frac{2TP}{2TP+FP+FN} $$ scikit-learn接口： 12345678910from sklearn.metrics import f1_scorey_true = [0, 1, 2, 0, 1, 2]y_pred = [0, 2, 1, 0, 0, 1]f1_score(y_true, y_pred, average=&#x27;macro&#x27;)f1_score(y_true, y_pred, average=&#x27;micro&#x27;)f1_score(y_true, y_pred, average=&#x27;weighted&#x27;)f1_score(y_true, y_pred, average=None) ROC和AUC 定义： ROC曲线，是以FPR(False Positive Rate, 召回率) 为横轴、TPR(True Positive Rate, 取伪率)为纵轴，衡量二分类系统性能的曲线。分类器对分类的置信度一般设为50%，即置信度超过50%认为是正例，低于50%认为是反例。依次改变这个置信度为10%~100%，会得到一组不同的混淆矩阵，取其中的FPR和TPR值组成坐标，连接这些值，就得到ROC曲线。ROC曲线与X轴围成的图形面积可以作为一个综合衡量指标，即AUC（Area Under Curve，曲线下面积）。AUC越大，曲线就越凸，分类器的效果也就越好。ROC曲线反映了分类器对正例的覆盖能力和对负例的覆盖能力之间的权衡。 scikit-learn接口： 12345678import numpy as npfrom sklearn.metrics import roc_curve, auc, roc_auc_scorey = np.array([1,1,2,2])pred = np.array([0.1,0.4,0.35,0.8])fpr,tpr,thresholds = roc_curve(y,pred,pos_label=2)result = auc(fpr,tpr)print(result) AP/MAP 定义：我们首先引入PR曲线概念。PR曲线（Precision-recall曲线）与ROC曲线的区别是横轴和纵轴不同，PR曲线的横轴Recall也就是TPR，反映了分类器对正例的覆盖能力。而纵轴Precision的分母是识别为正例的数目，而不是实际正例数目。Precision反映了分类器预测正例的准确程度。那么，PR曲线反映了分类器对正例的识别准确程度和对正例的覆盖能力之间的权衡。对于随机分类器而言，其Precision固定的等于样本中正例的比例，不随recall的变化而变化。与AUC相似，AP（Average Precision）就是PR曲线与X轴围成的图形面积， 若PR曲线为连续型，则： $$ AP=\\int_{0}^{1} PR, \\mathrm{d}r $$ 若PR曲线为离散型，则： $$ AP=\\sum_{k=1}^n P(K)\\Delta r(k) $$ 在信息检索领域，我们引入MAP(Mean Average Precision, 均值平均精度)， $$ MAP=\\frac{\\sum_{q=1}^Q AP(q)}{Q} $$ 其中Q为查询的总次数。 AP计算方法：前面给出的是AP的定义式，下面我们将介绍在信息检索领域计算AP的方法。首先求出每个位置上的精确率（Precision），然后求所有的位置的精确率（Precision）的平均值。如果该位置的文档是不相关的则该位置 Precision=0。 $$ AP=\\frac{\\sum_{k=1}^n (P(k)\\times rel(k))}{number\\ of\\ relevant\\ documents} $$ 注：其中k是返回结果序列的排列次序，n是返回结果的数目，P(k)是返回序列中从第k个文档处截断的精确率，rel(k)是指示函数，如果第k个文档为相关文档则rel(k)=1，否者rel(k)=0。 例如： Prediction Correctness Points 1 wrong 0 2 right 1 / 2 3 right 2 / 3 4 wrong 0 5 right 3 / 5 6 wrong 0 7 wrong 0 8 wrong 0 9 right 4 / 9 10 wrong 0 上表中Prediction列表示文档的得分排序结果，Correctness列表示结果的正确性，Points列为精确率得分。那么我们将计算得到AP=(0+1/2+2/3+0+3/5+0+0+0+4/9+0)/4=0.55。 MAP计算方法：主集合的平均准确率(MAP)是每个主题的平均准确率（AP）的平均值。假设在测试集中一共有k个类别。我们先算出我们的模型对于每个类别的AP，然后将这些AP相加在一起再除以所有类别的数量k，就可以得到最终模型的MAP。 例如：假设有两个主题，主题1有4个相关网页，主题2有3个相关网页。对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83；对于主题2检索出3个相关网页，其rank分别为1,3,5，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP= (0.83+0.45)/2=0.64。 scikit-learn接口： 123456import numpy as npfrom sklearn.metrics import average_precision_scorey_true = np.array([0, 0, 1, 1])y_scores = np.array([0.1, 0.4, 0.35, 0.8])result = average_precision_score(y_true, y_scores) # 计算APprint(result) MRR 定义：MRR(Mean Reciprocal Rank, 平均倒数排名)把标准答案在搜索结果中分数的排序取倒数作为它的准确度，再对所有的问题取平均。例如： Query Results Correct response Rank Reciprocal Rank cat catten, cati, cats cats 3 1/3 torus torri, tori, toruses tori 2 1/2 virus viruses, virii, viri viruses 1 1 注：黑体为返回结果中最匹配的一项 上表中的MRR=(1/3 + 1/2 + 1)/3 = 11/18=0.61 公式： $$ MRR=\\frac{1}{Q}\\sum_{i=1}^{|Q|} \\frac{1}{rank_i} $$ 其中|Q|是查询个数，$rank_i$是第i个查询相对于第一个相关的结果所在的排列位置。 scikit-learn接口： 123456import numpy as npfrom sklearn.metrics import label_ranking_average_precision_scorey_true = np.array([[1, 0, 0], [0, 0, 1]])y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])result = label_ranking_average_precision_score(y_true, y_score)print(result) NDCG 定义：NDCG(Normalized Discounted Cumulative Gain, 归一化折损累计增益)，在MAP中，四个文档和query要么相关，要么不相关，即相关度只能是0或1。NDCG对MAP进行了改进，相关度分成从0到r等级。当取r=5时，等级设定如下图所示： Relevance Rating Gain Perfect $31=2^5-1$ Excellent $15=2^4-1$ Good $7=2^3-1$ Fair $3=2^2-1$ xxx $1=2^1-1$ Bad $0=2^0-1$ 我们将这些增益相加就是CG(Cumulative Gain，累计增益,),CG就是将每个推荐结果相关性的分支累加后作为整个推荐列表的得分。 $$ CG_k=\\sum_{i=1}^k{rel_i} $$ 其中$rel_i$表示处于位置i的推荐结果的相关性。 Relevance Rating Gain Cumulative Gain #1 http://abc.go.com/ 31 31=31x1 #2 http://www.abcteach.com/ 3 34=31+3 #3 http://abcnews.go.com/sections/scitech/ 15 49=31+3+15 #4 http://www.abc.net.au/ 15 64=31+3+15+15 #5 http://abcnews.go.com/ 15 79=31+3+15+15+15 #6 … … … 考虑到一般情况下用户会优先点选排在前面的搜索结果，所以应该引入一个折算因子(discounting factor)，这时将计算得到DCG(Discounted Cumulative Gain)值。 $$ DCG_k=\\sum_{i=1}^k \\frac{2^{rel_i}-1}{log_2 (i+1)} $$ Relevance Rating Gain Discounted Cumulative Gain #1 http://abc.go.com/ 31 31=31x1 #2 http://www.abcteach.com/ 3 32.9=31+3x0.63 #3 http://abcnews.go.com/sections/scitech/ 15 40.4=32.9+15x0.50 #4 http://www.abc.net.au/ 15 46.9=40.4+15x0.43 #5 http://abcnews.go.com/ 15 52.7=46.9+15x0.39 #6 … … … 最后我们对DCG进行归一化得到NDCG(Normalized Discounted Cumulative Gain,归一化折损累计增益)。 $$ NDCG_k=\\frac{DCG_k}{IDCG_k} $$ 其中IDCG(Ideal DCG)，指推荐系统为某一用户返回的最好推荐结果列表，即假设返回结果按照相关性排序，最相关的结果放在前面，此序列的DCG为IDCG。因此DCG的值介于(0, IDCG]，故NDCG的值介于(0,1]。 评估方法实现 参考 [1]: Precision and recall [2]: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval) [3]: Precision/Recall、ROC/AUC、AP/MAP等概念区分 [4]: IR的评价指标-MAP,NDCG和MRR [5]: Mean reciprocal rank [6]: 二分类模型评估指标的计算方法与代码实现 [7]: Discounted cumulative gain [8]: 一个评测指标就是MAP(Mean Average Precision)平均精度均值。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://chiang97912.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"模型评估","slug":"模型评估","permalink":"http://chiang97912.github.io/tags/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"},{"name":"Accuracy","slug":"Accuracy","permalink":"http://chiang97912.github.io/tags/Accuracy/"},{"name":"Precision","slug":"Precision","permalink":"http://chiang97912.github.io/tags/Precision/"},{"name":"Recall","slug":"Recall","permalink":"http://chiang97912.github.io/tags/Recall/"},{"name":"F1","slug":"F1","permalink":"http://chiang97912.github.io/tags/F1/"},{"name":"ROC","slug":"ROC","permalink":"http://chiang97912.github.io/tags/ROC/"},{"name":"AUC","slug":"AUC","permalink":"http://chiang97912.github.io/tags/AUC/"},{"name":"MAP","slug":"MAP","permalink":"http://chiang97912.github.io/tags/MAP/"},{"name":"MRR","slug":"MRR","permalink":"http://chiang97912.github.io/tags/MRR/"},{"name":"NDCG","slug":"NDCG","permalink":"http://chiang97912.github.io/tags/NDCG/"}]},{"title":"轻量级Git服务Gogs搭建教程","slug":"轻量级Git服务Gogs搭建教程","date":"2019-12-30T13:37:48.000Z","updated":"2025-12-13T12:17:39.262Z","comments":true,"path":"2019/12/30/轻量级Git服务Gogs搭建教程/","permalink":"http://chiang97912.github.io/2019/12/30/%E8%BD%BB%E9%87%8F%E7%BA%A7Git%E6%9C%8D%E5%8A%A1Gogs%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","excerpt":"前言 Gogs是一个类似于Gitlab的开源Git服务，它具有易安装、跨平台、轻量级等特点。相比于Gitlab它的资源占有率极低，对于个人开发者或者小型团队是非常实用的一款Git服务。","text":"前言 Gogs是一个类似于Gitlab的开源Git服务，它具有易安装、跨平台、轻量级等特点。相比于Gitlab它的资源占有率极低，对于个人开发者或者小型团队是非常实用的一款Git服务。 创建系统用户 创建新的系统用户 “git”，并切换为 “git” 用户: 12sudo useradd -m gitsudo su - git 创建数据库 创建新的数据库并命名为gogs： 1mysql&gt;create database gogs; 安装Gogs 本文以v0.11.53 版本为例，最新版本读者可以前往dl.gogs.io查看： 12wget https://dl.gogs.io/0.11.53/gogs_0.11.53_linux_amd64.tar.gztar xzvf gogs_0.11.53_linux_amd64.tar.gz 运行Gogs 进入解压后的文件夹，然后执行命令： 1./gogs web 最后浏览器访问http://:3000完成相应的配置即可。 问题 Gogs不支持移动适配，但是它的开源分支Gitea支持，且Gitea的安装流程基本和Gogs一致。","categories":[{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://chiang97912.github.io/tags/Git/"},{"name":"Gogs","slug":"Gogs","permalink":"http://chiang97912.github.io/tags/Gogs/"},{"name":"Gitea","slug":"Gitea","permalink":"http://chiang97912.github.io/tags/Gitea/"}]},{"title":"Pyinstaller打包Python程序攻略","slug":"Pyinstaller打包Python程序攻略","date":"2019-08-25T08:38:04.000Z","updated":"2025-12-13T12:15:59.369Z","comments":true,"path":"2019/08/25/Pyinstaller打包Python程序攻略/","permalink":"http://chiang97912.github.io/2019/08/25/Pyinstaller%E6%89%93%E5%8C%85Python%E7%A8%8B%E5%BA%8F%E6%94%BB%E7%95%A5/","excerpt":"PyInstaller基本使用方法 下面列举几个常见的可选参数： 12345678910pyinstaller [options] my_script.py[options]: -h 显示帮助并退出 -D 生成一个文件夹，其中包含一个可执行文件（默认） -F 生成单个可执行文件 -w 生成一个无命令行界面的程序 -i file.ico 指定图标 --add-data SRC;DEST 在程序中用到的其他（非二进制）文件，不建议用 --hidden-import MODULENAME 在程序中隐式导入的库，可多次使用 --exclude-module MODULENAME 不希望导入的库，可多次使用 更详细的使用方法可以参看官方手册，本文不再赘述。","text":"PyInstaller基本使用方法 下面列举几个常见的可选参数： 12345678910pyinstaller [options] my_script.py[options]: -h 显示帮助并退出 -D 生成一个文件夹，其中包含一个可执行文件（默认） -F 生成单个可执行文件 -w 生成一个无命令行界面的程序 -i file.ico 指定图标 --add-data SRC;DEST 在程序中用到的其他（非二进制）文件，不建议用 --hidden-import MODULENAME 在程序中隐式导入的库，可多次使用 --exclude-module MODULENAME 不希望导入的库，可多次使用 更详细的使用方法可以参看官方手册，本文不再赘述。 问题：打包后程序体积太大 由于笔者使用的是Anaconda作为Python环境，最近有个项目需要将Python代码打包成可执行文件。在之前的需求中没有使用科学计算库（例如numpy、pandas等）所以打包出来的结果也就10M左右，完全可以接受。但是最近在项目中使用了numpy等科学计算库之后，程序打包的结果接近1G左右，这样的打包结果简直令人窒息。这里主要有两个解决方案：1. 使用虚拟环境打包 2. 使用纯净版本的Python打包 推荐使用第二种方法。 使用虚拟环境打包 Python虚拟环境有Anaconda、virtualenv以及pipenv，但是Anaconda打包的程序体积太大，所以我们需要避开Anaconda。本文主要介绍的虚拟环境是pipenv，它是pip和virtualenv的结合，所以使用起来也更加方便，另外值得一提的是，pipenv和requests（Python网络请求包）是同一个作者。 Pipenv使用教程 安装pipenv 1pip install pipenv 创建虚拟环境 首先进入你的项目所在目录，然后输入下面的命令安装虚拟环境： 1pipenv install --python path\\to\\python 注： &quot;path\\to\\python&quot;是python.exe可执行程序的路径，可以是Anaconda版本的Python也可以是本地纯净版本的Python。因为我们需要避开Anaconda所以读者最好自己前往Python官网下载纯净版本的Python，然后通过上面命令安装虚拟环境。 激活虚拟环境 1pipenv shell 输入上面的命令之后我们就进入了虚拟环境，然后我们可以像平时一样使用Python。 安装依赖库 在虚拟环境下安装 Pyinstaller 和你自己的脚本依赖的第三方库 1234pipenv install pyinstallerpipenv install numpypipenv install pandaspipenv install matplotlib 当然也可以进入虚拟环境后直接使用pip进行安装。 问题：ModuleNotFoundError pyinstaller打包成功后运行程序提示ModuleNotFoundError: No module named 'distutils’错误解决办法。 问题分析：由于pandas需要调用distutils库（Python自带），但是最新版本的virtualenv和pyinstaller存在兼容性问题，即打包的时候会遗漏distutils库，目前这个BUG还没有得到解决。当然Github上也有很多解决办法，具体可以参考这里。 解决方法：由于16.1版本的virtualenv可以正常使用，所以我们可以降级安装virtualenv。1. 首先我们需要卸载新版的virtualenv，然后安装16.1版本的virtualenv；2. 卸载原来的虚拟环境，然后使用16.1版本的virtualenv重新安装虚拟环境（使用pipenv安装）；3. 最后安装相关的依赖库重新打包即可。 使用纯净版本的Python打包 由于本地已经存在Anaconda环境，所以如果我们想再安装纯净版本的Python可以使用虚拟机，但是使用虚拟机安装Python需要安装虚拟机软件，然后安装Windows镜像，步骤过于繁琐，所以我们可以另辟蹊径——使用临时环境变量。 首先前往Python官网下载纯净的Python环境并安装到本地，然后我们可以通过下面的批处理脚本设置临时环境变量，为了方便可以将下面的脚本保存到batch脚本文件中（例如命名为set_python_path.bat），并将该脚本放到c:\\windows中，这样我们就可以在任何目录下切换Python环境了。 set_python_path.bat: 12345678910@echo offset conda_path=d:\\anaconda3set python_path=d:\\program files\\python36rem Approach one: Replace the anaconda installation path with the new python installation pathcall call set path=%%path:%conda_path%=%python_path%%%rem Approach two: Let the new python installation path overwrite the anaconda installation pathrem set path=%python_path%;%python_path%\\Scripts;%path% 上面的代码中conda_path是Anaconda的安装路径，python_path是纯净版本的Python安装路径。设置临时的Python环境变量主要有两种方法：方法一是替换环境变量中Anaconda安装路径为纯净版本的Python安装路径；方法二是将纯净版本的Python安装路径放到所有路径之前这样就可以覆盖Anaconda的路径。 我们在运行完上面的脚本之后就可以切换到新的Python环境，然后安装Pyinstaller和相关的依赖包进行打包。 最后 使用上面两者方法之一，原先接近1G的程序，现在只有40M左右。 Enjoy it!","categories":[{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"Pyinstaller","slug":"Pyinstaller","permalink":"http://chiang97912.github.io/tags/Pyinstaller/"},{"name":"python程序打包","slug":"python程序打包","permalink":"http://chiang97912.github.io/tags/python%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85/"},{"name":"pipenv","slug":"pipenv","permalink":"http://chiang97912.github.io/tags/pipenv/"},{"name":"virtualenv","slug":"virtualenv","permalink":"http://chiang97912.github.io/tags/virtualenv/"}]},{"title":"使用VIM作为IDE","slug":"使用VIM作为IDE","date":"2019-08-01T02:40:24.000Z","updated":"2025-12-13T12:18:36.570Z","comments":true,"path":"2019/08/01/使用VIM作为IDE/","permalink":"http://chiang97912.github.io/2019/08/01/%E4%BD%BF%E7%94%A8VIM%E4%BD%9C%E4%B8%BAIDE/","excerpt":"Windows环境 插件管理器 VIM的插件管理器主要有vim-plug和vundle","text":"Windows环境 插件管理器 VIM的插件管理器主要有vim-plug和vundle Vim-plug 首先下载vim-plug，可以去github下载 下载完成后解压压缩包将plug.vim复制到vim安装目录下的autoload文件夹下，即可完成vim-plug的安装。 使用管理员身份运行gvim,，然后点击gvim的“编辑”——“启动设定”，打开_vimrc配置文件。 插件安装示例 在_vimrc中添加如下的内容，这里以vim-plug下载nerdtree插件为例。设置完成后保存设置。 123call plug#begin(&#x27;~/.vim/plugged&#x27;) &quot;插件保存的目录Plug &#x27;scrooloose/nerdtree&#x27;, &#123;&#x27;on&#x27;: &#x27;NERDTreeToggle&#x27;&#125; &quot;NERDTree插件call plug#end() 常用操作 命令 解释 :PlugStatus 查看插件安装状态 :PlugInstall 安装在_vimrc中配置的插件。注意命令的大小写，执行后vim-plug会自动克隆并安装插件 :PlugUpdate 更新插件 :PlugClean 清理插件（需要先在_vimrc中删除或注释） :PlugUpgrade 更新vim-plug Vundle 首先下载vundle，可以去github下载 下载完成后解压压缩包到vim安装目录下的bundle文件夹下（没有就新建），即可完成vundle的安装。 使用管理员身份运行gvim,，然后点击gvim的“编辑”——“启动设定”，打开_vimrc配置文件。 插件安装示例 在_vimrc中添加如下的内容，这里以vundle下载nerdtree插件为例。设置完成后保存设置。 12345set rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()Plugin &#x27;VundleVim/Vundle.vim&#x27;Plugin &#x27;scrooloose/nerdtree&#x27;call vundle#end() 常用操作 命令 解释 :PluginList 查看插件安装状态 :PluginInstall 安装在_vimrc中配置的插件。注意命令的大小写，执行后vundle会自动克隆并安装插件 :PluginUpdate 更新插件 :PluginClean 清理插件（需要先在_vimrc中删除或注释） :PluginSearch 搜索插件，例如:PluginSearch xml可以搜到xml相关的插件 Python自动补全 Python自动补全插件这里主要使用jedi-vim，具体配置步骤如下： 在_vimrc中添加如下的内容，设置完成后保存设置。 1234&quot;插件管理 vim-plugcall plug#begin(&#x27;~/.vim/plugged&#x27;) &quot;插件保存的目录Plug &#x27;davidhalter/jedi-vim&#x27;,call plug#end() 然后在gvim中输入:PlugInstall安装jedi-vim插件 注意: Vim和版本一定要和Python相匹配，即32位Vim配32位Python, 64位Vim配64位Python。 Vim使用Python编译的版本一定要和电脑上安装的Python版本对应，可能会出现如下错误： 1Error: jedi-vim failed to initialize Python: jedi-vim requires Vim with support for Python 2 or 3. (in function jedi#init_python[4]..48_init_python, line 10) 或者在gvim中输入:python3 print(&quot;Hello world&quot;)出现如下类似的错误： 12E370: Could not load library python37.dllE263: Sorry, this command is disabled, the Python library could not be loaded. 那么可以在_vimrc中添加如下命令指定Python3版本： 1set pythonthreedll=python36.dll 由于笔者安装的vim8.1使用的是Python3.7编译，但是电脑环境装的是Python3.6，我们可以通过上面配置来解决Windows环境中gvim不支持python3.6的问题。 C/C++自动补全 C/C++自动补全插件这里主要使用ctags + OmniCppComplete方案，具体配置步骤如下： Ctags 全名 Exuberant Ctags，是一个独立的程序。它可以为各种语言的源代码生成语言元素（language object）索引文件。对于 C/C++ 而言，就是把源代码中的各种宏、函数、类、类成员等等元素和它们的相关信息生成索引文件，供其它程序使用。OmniCppComplete 是专为 C/C++ 编写的OmniComplete一个补全脚本，它根据 Ctags 生成的索引文件对代码进行补全。 安装Ctags 从Ctags官网下载 Ctags 可执行文件 将下载到的文件（仅 EXE 文件即可）解压到一个目录，例如 C:/ctags 将该目录加入环境变量 PATH 生成索引文件 以生成 C++ 标准库索引文件为例： 下载专为 Ctags 修改过的 libstdc++ 头文件 将其解压到一个目录，例如 C:/ctags/cpp_src 使用命令行进入 D:/ctags/cpp_src 后执行： 1ctags -R --sort=1 --c++-kinds=+p --fields=+iaS --extra=+q --language-force=C++ -f cpp . 建议将上一步生成的 C:/ctags/cpp_src/cpp 文件放到一个专门放置索引文件的目录以便后面的统一设置，例如放到 C:/ctags/tags 其它库的索引文件也可以依法炮制，只需切换到该库的 include 文件夹，执行： 1ctags -R --sort=yes --c++-kinds=+p --fields=+iaS --extra=+q --language-force=C++ -f &lt;文件名&gt; . 安装OmniCppComplete 使用插件管理器安装OmniCppComplete 修改VIM配置文件_vimrc，加入如下内容： 1234567891011121314151617&quot; ctags 索引文件set tags+=C:/ctags/tags/cpp &quot; 指定tags存放路径&quot; OmniCppCompletelet OmniCpp_NamespaceSearch = 1let OmniCpp_GlobalScopeSearch = 1let OmniCpp_ShowAccess = 1let OmniCpp_ShowPrototypeInAbbr = 1 &quot; 显示函数参数列表let OmniCpp_MayCompleteDot = 1 &quot; 输入 . 后自动补全let OmniCpp_MayCompleteArrow = 1 &quot; 输入 -&gt; 后自动补全let OmniCpp_MayCompleteScope = 1 &quot; 输入 :: 后自动补全let OmniCpp_DefaultNamespaces = [&quot;std&quot;, &quot;_GLIBCXX_STD&quot;]&quot; 自动关闭补全窗口au CursorMovedI,InsertLeave * if pumvisible() == 0|silent! pclose|endifset completeopt=menuone,menu,longestfiletype plugin indent on 在插入模式编辑 C/C++ 源文件时按下 . 或 -&gt; 或 ::，或者手动按下 Ctrl+X Ctrl+O 后就会弹出自动补全窗口，此时可以用 Ctrl+N 和 Ctrl+P 上下移动光标进行选择。 自动生成tags文件 omni插件的补全是依赖于tags文件的，因此需要我们手动建立tags文件: 1ctags -R --sort=yes --c++-kinds=+p --fields=+iaS --extra=+q --language-force=C++ 我们可以通过下面的代码让vim在保存文件后自动生成tags文件: 1au BufWritePost *.c,*.cpp,*.cc,*.h silent! !ctags -R --sort=yes --c++-kinds=+p --fields=+iaS --extra=+q --language-force=C++ 其中silent!表示静默运行命令，不然每次保存文件的时候，Vim 总是会有一个”ctags 执行完毕“的提示，按任意键确认。 生产力插件 Python代码检查：flake8 实用插件管理器安装flake8 配置_vimrc文件 1au BufWritePost *.py call Flake8() 注释/取消注释：vim-commentary 这个插件可以快速注释与反注释多行内容, 但是它的注释符使用的是 commentstring, 默认是 /* %s */, 但这个值满足不了Python 和 Shell这样的语言, 在 _vimrc 添加如下内容 1234&quot;为python和shell等添加注释autocmd FileType python,shell,coffee set commentstring=#\\ %s&quot;修改注释风格autocmd FileType java,c,cpp set commentstring=//\\ %s 普通模式下gcc 指令可以注释/取消注释 可视模式下gc 命令可以注释/撤销注释 缩进提示：indentLine indentLine是一款Vim下用于显示缩进指示线的插件。对于Python、Golang等靠代码缩进来标识代码块的语言来说，indentLine提供的缩进指示功能非常有用。indentLine安装之后即可使用，不需要额外的配置。 设置indentLine： 123set list lcs=tab:\\|\\ &quot; 最后面有空格let g:indentLine_leadingSpaceChar = &#x27;.&#x27;let g:indentLine_leadingSpaceEnabled = 1 实用配置 代码折叠 123&quot; Enable foldingset foldmethod=syntax &quot; 语法折叠set foldlevelstart=99 &quot; 关闭自动折叠 zc 关闭折叠 zo 打开折叠 za 打开/关闭折叠互相切换 系统剪贴板 通常Vim会忽视系统剪贴板，而使用自带的剪贴板。但是有时候你想从Vim之外的程序中剪切、复制、粘贴文本。你可以通过这行代码访问你的系统剪贴板： 1set clipboard=unnamed 禁止生成缓存文件 每次输入保存命令之后系统都会生成以.un~和.bak结尾的文件，我们可以通过下面的配置禁止vim生成undo文件和备份文件: 123set noundofileset nobackupset noswapfile 主题插件 主题插件推荐使用flazz/vim-colorschemes 可以使用vim-plug安装，然后再配置_vimrc文件，例如在配置文件中增加下面的代码： 1colorscheme wombat Mac &amp; Linux环境 插件管理器安装 使用如下命令安装plug-vim插件: 123mkdir -vp ~/.vim/autoload/cd ~/.vim/autoload/wget https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 安装示例 仍然以NERDTree插件安装为例： 编辑配置文件vim ~/.vimrc 1234&quot;插件管理 vim-plugcall plug#begin(&#x27;~/.vim/plugged&#x27;) &quot;插件保存的目录Plug &#x27;scrooloose/nerdtree&#x27;, &#123;&#x27;on&#x27;: &#x27;NERDTreeToggle&#x27;&#125; &quot;NERDTree插件call plug#end() 其他操作和Windows系统相同。","categories":[{"name":"VIM","slug":"VIM","permalink":"http://chiang97912.github.io/categories/VIM/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://chiang97912.github.io/tags/Python/"},{"name":"VIM","slug":"VIM","permalink":"http://chiang97912.github.io/tags/VIM/"},{"name":"C/C++","slug":"C-C","permalink":"http://chiang97912.github.io/tags/C-C/"}]},{"title":"Mask矩阵在深度学习中的应用","slug":"Mask矩阵在深度学习中的应用","date":"2019-07-31T17:20:49.000Z","updated":"2025-12-13T12:16:16.604Z","comments":true,"path":"2019/08/01/Mask矩阵在深度学习中的应用/","permalink":"http://chiang97912.github.io/2019/08/01/Mask%E7%9F%A9%E9%98%B5%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"定义 mask矩阵是一个由0和1组成的矩阵。在NLP中，一个常见的问题是输入序列长度不等，而mask可以帮助我们处理。虽然RNN等模型可以处理不定长的输入，但是在实践中，需要对输入中长度较短的句子进行填充，即在句尾填充0占位，转换成固定大小的tensor，方便矩阵操作。","text":"定义 mask矩阵是一个由0和1组成的矩阵。在NLP中，一个常见的问题是输入序列长度不等，而mask可以帮助我们处理。虽然RNN等模型可以处理不定长的输入，但是在实践中，需要对输入中长度较短的句子进行填充，即在句尾填充0占位，转换成固定大小的tensor，方便矩阵操作。 举个例子： 12case 1: I like cats.case 2: He does not like cats. 假设默认的序列长度是5，一般会对case 1做pad处理，变成 1I like cats &lt;PAD&gt; &lt;PAD&gt; 在上述例子数字编码后，开始做embedding，而pad也会有embedding向量，但pad本身没有实际意义，参与训练可能还是有害的。因此，有必要维护一个mask tensor来记录哪些是真实的value，上述例子的两个mask如下： 121 1 1 0 01 1 1 1 1 后续再梯度传播中，mask起到了过滤的作用。 使用TensorFlow实现上述过程： 12345678import tensorflow as tfmaxlen = 5lengths = [[3, 5, 4], [1, 3, 2]]mask = tf.cast(tf.sequence_mask(lengths, maxlen), tf.float32)sess = tf.Session()mask = sess.run(mask)print(mask) 运行结果： 1234567[[[1. 1. 1. 0. 0.] [1. 1. 1. 1. 1.] [1. 1. 1. 1. 0.]] [[1. 0. 0. 0. 0.] [1. 1. 1. 0. 0.] [1. 1. 0. 0. 0.]]] 作用 使用mask矩阵是为了让那些被mask掉的tensor不会被更新。一个tensor T和同样大小的mask矩阵M相乘在梯度回传的时候，T对应mask为0的地方梯度为0。因此权重不会被更新。 语言模型中可以防止未来信息泄露 在语言模型中，常常需要从上一个词预测下一个词，而现阶段attention是标配，比如Transformer中的self attention，如果不做mask，在decoder的时候很容易把下一个词的信息泄露了，即按上诉例子，不能在预测like这个词时已经知道like后面的词了。使用mask矩阵可以很好的解决这一问题。 TensorFlow生成mask对角矩阵： 1234567891011121314151617import tensorflow as tfimport matplotlib.pyplot as pltdef subsequent_mask(size): &quot;Mask out subsequent positions.&quot; attn_mask = tf.ones([size, size]) mask = tf.matrix_band_part(attn_mask, -1, 0) return mask sess = tf.Session()mask = sess.run(subsequent_mask(10))print(mask)# Display matrixplt.matshow(mask)plt.show() 运行结果： 12345678910[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] 参考 [1]: Mask矩阵在深度学习中有哪些应用场景？ [2]: 浅谈mask矩阵","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"深度学习/NLP","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/tags/tensorflow/"},{"name":"Python","slug":"Python","permalink":"http://chiang97912.github.io/tags/Python/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://chiang97912.github.io/tags/Deep-Learning/"},{"name":"NLP","slug":"NLP","permalink":"http://chiang97912.github.io/tags/NLP/"}]},{"title":"Git常用操作记录","slug":"Git常用操作记录","date":"2019-03-24T07:26:30.000Z","updated":"2025-12-13T12:16:43.655Z","comments":true,"path":"2019/03/24/Git常用操作记录/","permalink":"http://chiang97912.github.io/2019/03/24/Git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95/","excerpt":"基本操作 Git基本配置（git config） git config可以配置git的参数，可以使用git config --list查看已经配置的git参数。其中有三个级别的保存位置，–system、–global、–local，分别表示所有用户（本系统）、当前用户（全局）、本地配置（当前目录），默认使用–local。","text":"基本操作 Git基本配置（git config） git config可以配置git的参数，可以使用git config --list查看已经配置的git参数。其中有三个级别的保存位置，–system、–global、–local，分别表示所有用户（本系统）、当前用户（全局）、本地配置（当前目录），默认使用–local。 配置用户名及邮箱 在使用Git提交前，必须配置用户名和邮箱，这些信息会永久保存到历史记录中。 12git config --global user.name &quot;Peter&quot;git config --global user.email Peter@gmail.com 创建Git仓库（git init） 可以直接调用git init初始化当前目录，即创建Git仓库。 获取Git仓库（git clone） 如果需要克隆远程仓库，可以使用git clone，比如： 1git clone https://github.com/tensorflow/tensorflow.git 提交更新 Git中每个文件都有三种状态：committed、staged、modified。它们之间关系如下： modified=&gt; staged=&gt; committed 如果你在本地修改了文件，则文件状态就变成modified；如果使用git add命令，文件的状态变成staged；如果使用git commit命令，文件的状态就变成commited。 还有一种文件状态，未跟踪状态（unversioned/untracked），通过使用git add可以把未跟踪状态变更为staged；通过git rm可以将staged或者committed状态变为未跟踪状态。 git status: 查看在你上次提交之后是否有修改。 git add: 将想要快照的内容写入缓存区 git commit: 将缓存区内容添加到仓库中 git rm: 如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 Changes not staged for commit 的提示。要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除，然后提交。可以用以下命令完成此项工作 查看提交历史（git log） 使用git log查看当前工程的所有提交的日志。 123git log --stat # 仅显示摘要选项git log --pretty=oneline # 定制记录格式git log --graph # 图像化分支和版本更新 远程仓库 可以使用git remote查看当前的远程库。 git remote -v可以显示对应的克隆地址。（对于多个远程仓库很有用） 添加远程仓库 git remote add [short_name] [url]可以添加新的远程仓库。 例如： 1git remote add origin https://github.com/username/projectname.git 修改远程仓库 方法一：修改命令 1git remote set-url origin [url] 注：[url]表示你的Github仓库地址。 方法二：先删除后添加 12git remote rm origingit remote add origin [url] 方法三：直接修改config文件 从远程仓库抓取数据 git fetch [remote-name]可以从远程仓库抓取数据到本地。 也可以使用git pull 推送数据到远程仓库 1git push [remote_name] [branch_name] 默认使用origin和master。 默认使用origin和master。 ⭐强制推送数据到远程仓库⭐ 我们可以使用git push --force origin master强制推送本地代码到远程仓库，这意味着将覆盖掉远程仓库的代码。（注：–force参数也可以使用-f替代） 查看远程仓库信息 1git remote show origin 远程仓库的删除和重命名 12git remote rename [old_name] [new_name]git remote rm [remote_name] 修改提交信息 第一种情况 如果需要修改的提交信息是最后一次提交并且没有推送（push），那么可以使用如下命令进行修改： 1git commit --amend -m &quot;your new comment&quot; 第二种情况 如果需要修改的不是最后一次提交的提交信息，那么我们需要使用git rebase命令 确定修改的提交 我们可以使用git log命令查看需要修改的提交是倒数第几次提交 指定变基对象 使用命令git rebase -i HEAD~n回退到倒数第n次提交。运行命令后会进入到编辑器，出现n条commit信息，要修改哪条就将其前面pick改成edit,保存并退出。 修改提交信息 经过变基之后我们可以像第一种情况一样使用git commit --amend命令修改提交信息（可以直接输入git commit --amend然后进入编辑器修改提交内容也可以使用-m直接指定新的提交内容）。 注：变基（rebase）和合并（merge）都是对分支进行操作，它们的不同之处在于变基可以修改历史。执行git commit --amend后会产生一个新的分支，如果需要保留当前分支则需要删除之前的分支，然后将当前分支命名为之前的分支名。 执行变基 执行git rebase –continue，如果提示Successfully rebased and updated则表示变基成功。 分支操作 显示所有分支 使用git branch可显示当前所有分支。 可以使用–merged和–no-merged查看已经合并、未合并的分支。 创建及切换分支 12git branch test # 创建testing 分支git checkout test # 切换到testing分支 也可以使用下面命令直接切换并创建分支 1git checkout -b test 注意切换分支时请保持工作目录没有未提交的修改。Git鼓励使用分支，处理完问题之后合并分支即可。 分支合并 将test分支合并到master（主分支）上，需要通过下面命令： 12git checkout mastergit merge test 合并之后可以使用git branch -d test删除分支。 如果合并时存在冲突，需要手工修改。 ⭐删除分支⭐ 删除test分支 1git branch -d test 主干更换 将某个分支设置为主干master，我们可以删除 master，把 dev head 打标成 master。 12git branch -D mastergit checkout -b master","categories":[{"name":"Git","slug":"Git","permalink":"http://chiang97912.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://chiang97912.github.io/tags/Git/"}]},{"title":"Tensorflow共享变量机制理解与应用","slug":"tensorflow共享变量机制理解与应用","date":"2019-02-25T00:33:21.000Z","updated":"2025-12-13T12:14:34.008Z","comments":true,"path":"2019/02/25/tensorflow共享变量机制理解与应用/","permalink":"http://chiang97912.github.io/2019/02/25/tensorflow%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E6%9C%BA%E5%88%B6%E7%90%86%E8%A7%A3%E4%B8%8E%E5%BA%94%E7%94%A8/","excerpt":"创建变量 Tensorflow创建变量有两种方式： tf.get_variable() tf.Variable() 它们的区别如下： 在 tf.name_scope下时，tf.get_variable()创建的变量名不受 name_scope 的影响，而且在未指定共享变量时，如果重名会报错，tf.Variable()会自动检测有没有变量重名，如果有则会自行处理。","text":"创建变量 Tensorflow创建变量有两种方式： tf.get_variable() tf.Variable() 它们的区别如下： 在 tf.name_scope下时，tf.get_variable()创建的变量名不受 name_scope 的影响，而且在未指定共享变量时，如果重名会报错，tf.Variable()会自动检测有没有变量重名，如果有则会自行处理。 12345678910111213141516import tensorflow as tfwith tf.name_scope(&#x27;name_scope_x&#x27;): var1 = tf.get_variable(name=&#x27;var1&#x27;, shape=[1], dtype=tf.float32) var3 = tf.Variable(name=&#x27;var2&#x27;, initial_value=[2], dtype=tf.float32) var4 = tf.Variable(name=&#x27;var2&#x27;, initial_value=[2], dtype=tf.float32)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(var1.name, sess.run(var1)) print(var3.name, sess.run(var3)) print(var4.name, sess.run(var4))# 输出结果：# var1:0 [-0.30036557] 可以看到前面不含有指定的&#x27;name_scope_x&#x27;# name_scope_x/var2:0 [ 2.]# name_scope_x/var2_1:0 [ 2.] 可以看到变量名自行变成了&#x27;var2_1&#x27;，避免了和&#x27;var2&#x27;冲突 如果使用tf.get_variable()创建变量，且没有设置共享变量，重名时会报错 12345678910111213import tensorflow as tfwith tf.name_scope(&#x27;name_scope_1&#x27;): var1 = tf.get_variable(name=&#x27;var1&#x27;, shape=[1], dtype=tf.float32) var2 = tf.get_variable(name=&#x27;var1&#x27;, shape=[1], dtype=tf.float32)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(var1.name, sess.run(var1)) print(var2.name, sess.run(var2))# ValueError: Variable var1 already exists, disallowed. Did you mean # to set reuse=True in VarScope? Originally defined at:# var1 = tf.get_variable(name=&#x27;var1&#x27;, shape=[1], dtype=tf.float32) 共享变量 基础写法 如果要共享变量，需要使用tf.variable_scope() 1234567891011121314151617181920import tensorflow as tfwith tf.variable_scope(&#x27;variable_scope_y&#x27;) as scope: var1 = tf.get_variable(name=&#x27;var1&#x27;, shape=[1], dtype=tf.float32) scope.reuse_variables() # 设置共享变量 var1_reuse = tf.get_variable(name=&#x27;var1&#x27;) var2 = tf.Variable(initial_value=[2.], name=&#x27;var2&#x27;, dtype=tf.float32) var2_reuse = tf.Variable(initial_value=[2.], name=&#x27;var2&#x27;, dtype=tf.float32)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(var1.name, sess.run(var1)) print(var1_reuse.name, sess.run(var1_reuse)) print(var2.name, sess.run(var2)) print(var2_reuse.name, sess.run(var2_reuse))# 输出结果：# variable_scope_y/var1:0 [-1.59682846]# variable_scope_y/var1:0 [-1.59682846] 可以看到变量var1_reuse重复使用了var1# variable_scope_y/var2:0 [ 2.]# variable_scope_y/var2_1:0 [ 2.] 或者如下形式： 1234with tf.variable_scope(&#x27;foo&#x27;) as foo_scope: v = tf.get_variable(&#x27;v&#x27;, [1])with tf.variable_scope(&#x27;foo&#x27;, reuse=True): v1 = tf.get_variable(&#x27;v&#x27;) 还可以像下面这样编写： 1234with tf.variable_scope(&#x27;foo&#x27;) as foo_scope: v = tf.get_variable(&#x27;v&#x27;, [1])with tf.variable_scope(foo_scope, reuse=True): v1 = tf.get_variable(&#x27;v&#x27;) 更优雅的写法 之前的几种写法是在重复使用（非第一次使用）的时候设置reuse=True来再次调用共享变量作用域（variable_scope），这是一种比较笨的方式，下面使用tf.AUTO_REUSE的写法或许更加优雅： 123with tf.variable_scope(&#x27;foo&#x27;, reuse=tf.AUTO_REUSE): v = tf.get_variable(&#x27;v&#x27;, [1]) v1 = tf.get_variable(&#x27;v&#x27;) 实例： 123456789101112131415161718192021222324252627import numpy as npimport tensorflow as tfdef convolution(in_put, in_channel, out_channel): with tf.variable_scope(name_or_scope=&#x27;&#x27;, reuse=tf.AUTO_REUSE): weights = tf.get_variable(name=&quot;weights&quot;, shape=[2, 2, in_channel, out_channel], initializer=tf.contrib.layers.xavier_initializer_conv2d()) output = tf.nn.conv2d(input=in_put, filter=weights, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;) return outputdef main(): with tf.Graph().as_default(): input_x = tf.placeholder(dtype=tf.float32, shape=[1, 4, 4, 1]) for _ in range(5): output = convolution(input_x, 1, 1) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) _output = sess.run([output], feed_dict=&#123;input_x: np.random.uniform(low=0, high=255, size=[1, 4, 4, 1])&#125;) print(_output)if __name__ == &quot;__main__&quot;: main() reuse参数使用 当参数reuse=False，函数get_variable（）表示创建变量 123456789import tensorflow as tfwith tf.variable_scope(&quot;foo&quot;, reuse=False): v = tf.get_variable(&quot;v&quot;, [1], initializer=tf.constant_initializer(1.0)) v1 = tf.get_variable(&quot;v&quot;, [1])# 输出结果：# ValueError: Variable foo/v already exists, disallowed. # Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? 当参数reuse=True，函数get_variable（）表示获取变量 1234567891011import tensorflow as tfwith tf.variable_scope(&quot;foo&quot;): v = tf.get_variable(&quot;v&quot;, [1], initializer=tf.constant_initializer(1.0))with tf.variable_scope(&quot;foo&quot;, reuse=True): v1 = tf.get_variable(&quot;v&quot;, [1])print(v1 == v)# 输出结果：True 在tf.variable_scope()函数中，设置reuse=True时，在其命名空间&quot;foo&quot;中执行函数get_variable()时，表示获取变量&quot;v&quot;。若在该命名空间中还没有该变量，则在获取时会报错，实例如下： 12345678import tensorflow as tf with tf.variable_scope(&quot;foo&quot;, reuse=True): v1 = tf.get_variable(&quot;v&quot;,[1])# 输出结果：# ValueError: Variable foo/v does not exist, or was not created with tf.get_variable(). # Did you mean to set reuse=tf.AUTO_REUSE in VarScope? 参考 [1]: tensorflow里面name_scope, variable_scope等如何理解？ [2]: tf.AUTO_REUSE作用 [3]: TensorFlow中变量管理reuse参数的使用","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/categories/tensorflow/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/tags/tensorflow/"}]},{"title":"Ubuntu环境MYSQL乱码问题修复","slug":"Ubuntu环境MYSQL乱码问题修复","date":"2018-12-09T05:10:29.000Z","updated":"2025-12-13T12:14:03.174Z","comments":true,"path":"2018/12/09/Ubuntu环境MYSQL乱码问题修复/","permalink":"http://chiang97912.github.io/2018/12/09/Ubuntu%E7%8E%AF%E5%A2%83MYSQL%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D/","excerpt":"首先声明笔者使用的服务器是Ubuntu16.04，数据库安装的是Mysql 5.7。初始的mysql默认字符集是latin1，如果向数据库中插入中文就会出现乱码，下面我们通过修改配置文件的方式修改mysql的默认编码。","text":"首先声明笔者使用的服务器是Ubuntu16.04，数据库安装的是Mysql 5.7。初始的mysql默认字符集是latin1，如果向数据库中插入中文就会出现乱码，下面我们通过修改配置文件的方式修改mysql的默认编码。 修改配置文件 修改[mysqld] 找到文件/etc/mysql/mysql.conf.d/mysqld.cnf 中的[mysqld]并在其最后面追加如下代码： 1character-set-server=utf8 修改[mysql] 找到文件/etc/mysql/conf.d/mysql.cnf中的[mysql]并在其最后面追加如下代码： 1default-character-set=utf8 修改[client] 找到文件/etc/mysql/debian.cnf中的[client]并在其最后面追加如下代码： 1default-character-set=utf8 重启MYSQL 1service mysql restart 查看字符集 12mysql -u root -p show variables like &#x27;%character%&#x27;; 其他问题 笔者在做完如上配置之后发现通过navicat连接mysql查看内容还是出现乱码，但是其他地方返回的数据均能够正常显示。出现上述情况可以按照如下步骤进行操作： 右键–&gt;编辑连接–&gt;高级 将编码方式设置为自动","categories":[{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://chiang97912.github.io/tags/mysql/"}]},{"title":"LAMP环境搭建以及MYSQL远程访问配置","slug":"LAMP环境搭建以及MYSQL远程访问配置","date":"2018-12-04T03:51:55.000Z","updated":"2025-12-13T12:16:28.792Z","comments":true,"path":"2018/12/04/LAMP环境搭建以及MYSQL远程访问配置/","permalink":"http://chiang97912.github.io/2018/12/04/LAMP%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8AMYSQL%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%E9%85%8D%E7%BD%AE/","excerpt":"首先声明笔者使用的服务器是Ubuntu16.04。下面正式进入配置教程：","text":"首先声明笔者使用的服务器是Ubuntu16.04。下面正式进入配置教程： LAMP环境搭建 安装Apache2 1sudo apt-get install apache2 检查apache2是否安装成功 1apache2 –v 安装PHP7 1sudo apt-get install php 查看PHP版本并检查PHP是否按照成功 1php –v 安装MYSQL 12sudo apt-get install mysql-serversudo apt-get install mysql-client 安装配置组件 1234567sudo apt-get install libapache2-mod-phpsudo apt-get install libapache2-mod-auth-mysql # 现在这个组件作者以及放弃维护了，因为新版apache以及包含这个模块所实现的功能，可以不用安装sudo apt-get install php-mysqlsudo apt-get install php-gd # php图形库 启用mod_rewrite模块 1service apache2 restart 重启Apache2和MYSQL 12sudo service apache2 restartsudo service mysql restart 测试PHP 创建一个php文件来测试环境是否安装成功，PHP文件（文件名为test.php）内容： 123&lt;?php echo phpinfo();?&gt; 通过IP/test.php查看是否连接成功。 端口允许 通过上述步骤我们可能还是不能通过IP地址访问服务器，那是因为阿里云默认是没有开放80端口的，我们需要前往阿里云的控制台将80端口添加到安全组。 MYSQL远程访问配置 修改MYSQL配置 我们通过修改MYSQL的配置文件运行允许所有主机访问服务器上的MYSQL数据库： 使用vim编辑mysql的配置文件/etc/mysql/mysql.conf.d/mysqld.cnf 1vim /etc/mysql/mysql.conf.d/mysqld.cnf 然后修改文件中的bind-address的值为0.0.0.0 修改MYSQL用户访问权限 首先进入MYSQL数据库，使用mysql数据库: 1use mysql; 然后: 1update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;; 查看MYSQL用户权限： 1select host, user from user; have fun!","categories":[{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://chiang97912.github.io/tags/sql/"},{"name":"lamp","slug":"lamp","permalink":"http://chiang97912.github.io/tags/lamp/"},{"name":"linux","slug":"linux","permalink":"http://chiang97912.github.io/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"http://chiang97912.github.io/tags/mysql/"}]},{"title":"PHP接口返回500错误状态码解决方法","slug":"PHP接口返回500错误状态码解决方法","date":"2018-11-17T14:12:43.000Z","updated":"2025-12-13T12:16:08.956Z","comments":true,"path":"2018/11/17/PHP接口返回500错误状态码解决方法/","permalink":"http://chiang97912.github.io/2018/11/17/PHP%E6%8E%A5%E5%8F%A3%E8%BF%94%E5%9B%9E500%E9%94%99%E8%AF%AF%E7%8A%B6%E6%80%81%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"背景 最近在用PHP写用户登录接口，但是将PHP代码部署到生产环境却发生了错误，用浏览器访问接口产生错误状态码500如下： 1HTTP ERROR 500 这个错误是由于PHP代码存在错误引起的，但是默认PHP是关闭错误提示的。如果想要知道代码的错误必须先打开PHP的错误显示功能。","text":"背景 最近在用PHP写用户登录接口，但是将PHP代码部署到生产环境却发生了错误，用浏览器访问接口产生错误状态码500如下： 1HTTP ERROR 500 这个错误是由于PHP代码存在错误引起的，但是默认PHP是关闭错误提示的。如果想要知道代码的错误必须先打开PHP的错误显示功能。 解决方法 首先声明笔者使用的生产环境是Ubuntu 16.04。 第一步：先找到PHP的配置文件php.ini文件所在位置，这里笔者的Ubuntu中的php7的php.ini存在于路径/etc/php/7.0/apache2/下面，我们只需要使用vi/vim从上述路径下打开php.ini文件； 第二步：查找并修改php.ini文件中的display_errors和display_startup_errors中的值为On即可； 修改后的内容如下： 123#修改你的php.ini文件display_errors = Ondisplay_startup_errors = On 第三步：重启php-fpm。 1/etc/init.d/php7.0-fpm restart 更多版本php操作详见如下链接，另外还有appache2相关操作见如下链接。 到此为止就可以查看到错误信息了。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://chiang97912.github.io/categories/PHP/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://chiang97912.github.io/tags/PHP/"}]},{"title":"Python大数据量计数","slug":"Python大数据量计数","date":"2018-09-10T07:58:34.000Z","updated":"2025-12-13T12:15:38.079Z","comments":true,"path":"2018/09/10/Python大数据量计数/","permalink":"http://chiang97912.github.io/2018/09/10/Python%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E8%AE%A1%E6%95%B0/","excerpt":"和上一篇文章一样，这篇文章也是我在数学建模中碰到的，如果只是普通数据量的计数问题那么我们不妨使用counter，但是如果数据量达到一定规模，那么我们不得不考虑其他算法来解决问题了。我们这里使用hyperloglog算法来实现大数据量计数问题，这种算法是一种基于统计的计数算法，算法并不一定准确，但是足够快，如果读者将速度放在第一位那么不妨试试这种算法，而且hyperloglog算法准确率逼近100%，试问1000001和100000又有多大的差距呢，所以这种算法是有一定实用性的。","text":"和上一篇文章一样，这篇文章也是我在数学建模中碰到的，如果只是普通数据量的计数问题那么我们不妨使用counter，但是如果数据量达到一定规模，那么我们不得不考虑其他算法来解决问题了。我们这里使用hyperloglog算法来实现大数据量计数问题，这种算法是一种基于统计的计数算法，算法并不一定准确，但是足够快，如果读者将速度放在第一位那么不妨试试这种算法，而且hyperloglog算法准确率逼近100%，试问1000001和100000又有多大的差距呢，所以这种算法是有一定实用性的。 代码实现 当然作为胶水语言的Python，我们当然不必重复造轮子，这里我们可以直接使用python的bounter库来实现hyperloglog算法计数。 安装方法：pip install bounter 这里给出bounter在github上的官方教材使用的代码： 示例一： 1234567from bounter import bountercounts = bounter(size_mb=1024) # use at most 1 GB of RAMcounts.update([u&#x27;a&#x27;, &#x27;few&#x27;, u&#x27;words&#x27;, u&#x27;a&#x27;, u&#x27;few&#x27;, u&#x27;times&#x27;]) # count item frequenciesprint(counts[u&#x27;few&#x27;]) # query the counts2 示例二 12345678910111213from bounter import bountercounts = bounter(size_mb=200) # default version, unless you specify need_items or need_countscounts.update([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;])print(counts.total(), counts.cardinality()) # total and cardinality still work(5L, 3)print(counts[&#x27;a&#x27;]) # individual item frequency still works2print(list(counts)) # iterator returns keys, just like Counter[u&#x27;b&#x27;, u&#x27;a&#x27;, u&#x27;c&#x27;]print(list(counts.iteritems())) # supports iterating over key-count pairs, etc.[(u&#x27;b&#x27;, 2L), (u&#x27;a&#x27;, 2L), (u&#x27;c&#x27;, 1L)]","categories":[{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Python实现最近点对求解","slug":"Python实现最近点对求解","date":"2018-09-10T07:21:27.000Z","updated":"2025-12-13T12:15:08.259Z","comments":true,"path":"2018/09/10/Python实现最近点对求解/","permalink":"http://chiang97912.github.io/2018/09/10/Python%E5%AE%9E%E7%8E%B0%E6%9C%80%E8%BF%91%E7%82%B9%E5%AF%B9%E6%B1%82%E8%A7%A3/","excerpt":"数学建模中遇到求最近点对的问题，按理说我们使用朴素法进行暴力求解答案也是可行的，但是由于数据过于庞大，我们最初使用朴素法在计算机上跑了6个小时都没有得到问题的解，最终只得作罢。后来我们利用分治法解决了最近点对问题，具体思路参看这里。","text":"数学建模中遇到求最近点对的问题，按理说我们使用朴素法进行暴力求解答案也是可行的，但是由于数据过于庞大，我们最初使用朴素法在计算机上跑了6个小时都没有得到问题的解，最终只得作罢。后来我们利用分治法解决了最近点对问题，具体思路参看这里。 分治法 分治法解决最近点对问题的算法过程读者可以参见上文给出的参考博客。分治法的思想就是先将问题分解成一个个小的问题，最后将小问题的答案合并得到问题的解。这其中关键步骤是分解与合并，具体实现方法是使用递归，核心思想是空间换时间。 代码实现 上面给出的教程中是使用C++实现的，我这里给出Python实现。 由于我这里具体的问题是给出经纬度找出最近点对，所以我采用的距离为改进的球面余弦距离。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# -*- coding: utf-8 -*-from collections import Counterfrom math import sqrt,acos, sin, cos, radiansdef nearest_dot(s): mid = int(len(s)/2) left = s[0:mid] right = s[mid:] mid_x = (left[-1][0]+right[0][0])/2.0 if len(left) &gt; 2: lmin = nearest_dot(left) #左侧部分最近点对 else: lmin = left if len(right) &gt; 2: rmin = nearest_dot(right) #右侧部分最近点对 else: rmin = right if len(lmin) &gt;1: dis_l = get_distance(lmin) else: dis_l = float(&quot;inf&quot;) if len(rmin) &gt;1: dis_r = get_distance(rmin) else: dis_r = float(&quot;inf&quot;) d = min(dis_l, dis_r) #最近点对距离 mid_min=[] for i in left: if mid_x-i[0]&lt;=d : #如果左侧部分与中间线的距离&lt;=d for j in right: if abs(i[0]-j[0])&lt;=d and abs(i[1]-j[1])&lt;=d: #如果右侧部分点在i点的(d,2d)之间 if get_distance((i,j))&lt;=d: mid_min.append([i,j]) #ij两点的间距若小于d则加入队列 if mid_min: dic=[] for i in mid_min: dic.append(&#123;get_distance(i):i&#125;) dic.sort(key=lambda x: x.keys()) return list(dic[0].values())[0] elif dis_l&gt;dis_r: return rmin else: return lmin # 求点对的距离def get_distance(m): dx = m[0][1] - m[1][1] # 经度差值 dy = m[0][0] - m[1][0] # 纬度差值 # b = (lat1 + lat2) / 2.0 # 平均纬度 # Lx = (a[3] * b*b*b + a[2]* b*b + a[1] * b + a[0]) * radians(dx) * 6367000.0 # 东西距离(单位：米) Lx = cos(dx) * radians(dx) * 6367000.0 # 东西距离(单位：米) Ly = 6367000.0 * radians(dy) # 南北距离 return sqrt(Lx * Lx + Ly * Ly)def divide_conquer(s): s.sort() nearest_dots = nearest_dot(s) return nearest_dots","categories":[{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}]},{"title":"Python实现argsort排序返回索引值","slug":"python实现argsort排序返回索引值","date":"2018-09-05T12:58:14.000Z","updated":"2025-12-13T12:14:52.359Z","comments":true,"path":"2018/09/05/python实现argsort排序返回索引值/","permalink":"http://chiang97912.github.io/2018/09/05/python%E5%AE%9E%E7%8E%B0argsort%E6%8E%92%E5%BA%8F%E8%BF%94%E5%9B%9E%E7%B4%A2%E5%BC%95%E5%80%BC/","excerpt":"插曲是这样的，之前一直在给别人写外包程序，在程序中我使用到了numpy库中的argsort排序方法，这个排序方法十分方便，对可迭代对象进行排序并返回原顺序的索引值。由于程序要传给客户，所以我将代码封装成了exe可执行程序。之前封装出来的程序最多也就40来兆，可是自从我将开发环境切换到anaconda后，封装出来的程序高达200多兆，简直吓死我了。今天客户再次需要这个程序，于是我决定抛弃numpy库，自己实现argsort算法。","text":"插曲是这样的，之前一直在给别人写外包程序，在程序中我使用到了numpy库中的argsort排序方法，这个排序方法十分方便，对可迭代对象进行排序并返回原顺序的索引值。由于程序要传给客户，所以我将代码封装成了exe可执行程序。之前封装出来的程序最多也就40来兆，可是自从我将开发环境切换到anaconda后，封装出来的程序高达200多兆，简直吓死我了。今天客户再次需要这个程序，于是我决定抛弃numpy库，自己实现argsort算法。 numpy实现 首先来看看numpy库中argsort的用法： 1argsort(a, axis=-1, kind=&#x27;quicksort&#x27;, order=None) 第一个参数是需要排序的可迭代对象，第二个参数是排序的维度，第三个参数是排序的算法，常见的有快排（quicksort）、堆排序（heapsort）以及归并排序（mergesort）。第四个参数是排序的次序。 实例： 123456import numpy as npli = [1.5, 3, 15, 21, 7, 31, 5]indies = np.argsort(li, kind=&#x27;heapsort&#x27;)print(indies) 运行结果： 1[0 1 6 4 2 3 5] 原生python实现 其实原生python的实现主要是借用python内置函数sorted，但是sorted函数返回的结果是排序的最终结果而不是排序之前的索引值序列。但是我们可以利用sorted函数对字典排序的能力，将列表转换成字典就可以了。列表转字典的方法是先将列表通过enumerate函数转换成枚举型，然后在通过dict函数转换成字典。这样传入的列表就变为一个键为索引值为原值的一个字典了。这样我们再使用sorted函数对字典排序，再返回字典的键就可以了。 123456789def argsort(X): d = dict(enumerate(X)) r = dict(sorted(d.items(), key=lambda x:x[1])) return list(r.keys())li = [1.5, 3, 15, 21, 7, 31, 5]indies = argsort(li)print(indies) 运行结果： 1[0, 1, 6, 4, 2, 3, 5]","categories":[{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/categories/%E4%BB%A3%E7%A0%81/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/tags/%E4%BB%A3%E7%A0%81/"}]},{"title":"模糊综合评价法原理及实现","slug":"模糊综合评价法原理及实现","date":"2018-09-02T09:45:12.000Z","updated":"2025-12-13T12:19:01.049Z","comments":true,"path":"2018/09/02/模糊综合评价法原理及实现/","permalink":"http://chiang97912.github.io/2018/09/02/%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/","excerpt":"模糊综合评价法原理 基本思想 模糊综合评价法是一种基于模糊数学的综合评价方法。该综合评价法根据模糊数学的隶属度理论把定性评价转化为定量评价，即用模糊数学对受到多种因素制约的事物或对象做出一个总体的评价。它具有结果清晰，系统性强的特点，能较好地解决模糊的、难以量化的问题，适合各种非确定性问题的解决。","text":"模糊综合评价法原理 基本思想 模糊综合评价法是一种基于模糊数学的综合评价方法。该综合评价法根据模糊数学的隶属度理论把定性评价转化为定量评价，即用模糊数学对受到多种因素制约的事物或对象做出一个总体的评价。它具有结果清晰，系统性强的特点，能较好地解决模糊的、难以量化的问题，适合各种非确定性问题的解决。 隶属度 隶属函数，也称为归属函数或模糊元函数，是模糊集合中会用到的函数，是一般集合中指示函数的一般化。指示函数可以说明一个集合中的元素是否属于特定子集合。一元素的指示函数的值可能是0或是1，而元素的隶属函数会是0到1之间的数值，表示元素属于某模糊集合的“真实程度”（degree of truth）即隶属度。 基本模型 设评判对象为P: 其因素集 $ U={ u_1, u_2, \\cdots , u_n } $ ,评判等级集 $ V={ v_1, v_2, \\cdots ,v_m } $ 。对U中每一因素根据评判集中的等级指标进行模糊评判，得到评判矩阵： $$ R=\\begin{bmatrix} r{11},r{12},\\cdots,r{1m} \\ r{21},r{22},\\cdots,r{2m} \\ r{n1},r{n2},\\cdots,r_{nm} \\end{bmatrix} $$ 通常为了避免量纲的影响，我们还要进行去量纲操作。 其中，$r_{ij}$表示$u_i$关于$v_j$的隶属度。(U,V,R) 则构成了一个模糊综合评判模型。确定各因素重要性指标（也称权数）后，记为$A={ a_1,a_2, \\cdots,a_n }$,满足$\\sum_{i=1}^na_i=1$，合成得 $$ \\overline B = A\\cdot R=\\left(\\overline {b_1}, \\overline {b_2}, \\cdots ,\\overline {b_m} \\right) $$ 经归一化后，得 $ B= { b_i, b_2, \\cdots, b_m } $ ,于是可确定对象P的评判等级。 如果想得到综合得分，那么我们还可以对B进一步打分，即以同样的方式设置权数，对B进行综合评定。 对问题进行模糊综合分析之后我们通常还要考察该模型的置信度。 权数的确定： 权数可以通过数学方法来确定，也可以由具有权威性的专家及具有代表性的人按因素的重要程度来商定。不过现在通用的做法是凭经验给出权重。 合成算法： 合成算法即加权的方式，常见算法有： 主因素决定型 $$ b_i=\\max \\left { \\min \\left { a_1,r_{1i} \\right},\\min \\left { a_2,r_{2i} \\right} ,\\cdots,\\min \\left { a_n,r_{ni} \\right}\\right} $$ 主因素突出型 $$ b_i=\\max \\left { a_1\\times r_{1i}, a_2\\times r_{2i} ,\\cdots,a_n\\times r_{ni}\\right} $$ 加权平均型 $$ b_i=a_1\\times r_{1i} + a_2\\times r_{2i} +\\cdots+a_n\\times r_{ni} $$ 加权平均型算法常用在因素集很多的情形，它可以避免信息丢失；主因素突出型算法常用在所统计的模糊矩阵中的数据相差很悬殊的情形，它可以防止特殊数据的干扰。 实例：教学质量评价 我们首先按照票数结果统计了25名学生对某位老师的教学质量评价表，统计结果如下： 好（100） 较好（85） 一般（70） 较差（55） 1. 教学计划及教学内容安排（0.10） 9 14 2 0 2. 教材及参考资料状况（0.10） 3 14 7 1 3. 教师教学态度及责任心（0.15） 5 15 5 0 4. 教师讲解能力（0.10） 1 10 11 3 5. 课堂教学形式的多样化程度（0.10） 2 11 12 0 6. 理论联系实际程度及教学案例使用情况（0.10） 5 14 6 0 7. 辅助教学环节及考核情况（0.10） 4 6 13 2 8. 教学改革与创新情况（0.10） 3 8 12 2 9. 从本课程学习中所获得的收益程度（0.15） 5 12 6 2 由于我们最终要给每项指标打分，如果直接使用票数计算那么必然会导致结果收到参评人员数量的影响，即参评人数为1000和参评人数为25的结果截然不同，所以我们使用某项指标的某个等级票数的频率来代替票数来表示隶属度。各项因素的权数向量为：$[0.1, 0.1, 0.15, 0.10, 0.10, 0.10, 0.10,0.10, 0.15]$，评判等级的权数向量为:$[100, 85,70,55]$，其中两个权数向量之和为1。 好（100） 较好（85） 一般（70） 较差（55） 1. 教学计划及教学内容安排（0.10） 0.36 0.56 0.08 0.00 2. 教材及参考资料状况（0.10） 0.12 0.56 0.28 0.04 3. 教师教学态度及责任心（0.15） 0.20 0.60 0.2 0.00 4. 教师讲解能力（0.10） 0.04 0.4 0.44 0.12 5. 课堂教学形式的多样化程度（0.10） 0.08 0.44 0.48 0.00 6. 理论联系实际程度及教学案例使用情况（0.10） 0.20 0.56 0.24 0.00 7. 辅助教学环节及考核情况（0.10） 0.16 0.24 0.52 0.08 8. 教学改革与创新情况（0.10） 0.12 0.32 0.48 0.08 9. 从本课程学习中所获得的收益程度（0.15） 0.2 0.48 0.24 0.08 综合隶属度 0.168 0.47 0.318 0.044 综合隶属度由各项因素的权数向量和相应列的评判等级向量经过合成算法（这里使用加权平均）后的结果， 综合得分：0.168x100 + 0.47x85 + 0.318x70 + 0.044x55=81.43 代码实现 下面代码中的fuzzy_method为主函数，fuzzy_comprehensive_evaluation为模糊综合评价法的主要逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293function fuzzy_method % 模糊综合评价模型主函数 A1=[0.1 0.2 0.3 0.4]; A2=[0.4 0.35 0.15 0.1]; R=[0.2 0.5 0.2 0.1; 0.7 0.2 0.1 0; 0 0.4 0.5 0.1; 0.2 0.3 0.5 0]; fuzzy_comprehensive_evaluation(1,A1,R) fuzzy_comprehensive_evaluation(1,A2,R)endfunction B=fuzzy_comprehensive_evaluation(model,A,R) %模糊综合评判 % 参数model用于合成算法的确定，参数A为权数向量，参数R为隶属度矩阵。 B=[]; [m,s1]=size(A); [s2,n]=size(R); if(s1~=s2) disp(&#x27;A的列不等于R的行&#x27;); else if(model==1) %主因素决定型 for(i=1:m) for(j=1:n) B(i,j)=0; for(k=1:s1) x=0; if(A(i,k)&lt;R(k,j)) x=A(i,k); else x=R(k,j); end if(B(i,j)&lt;x) B(i,j)=x; end end end end elseif(model==2) %主因素突出型 for(i=1:m) for(j=1:n) B(i,j)=0; for(k=1:s1) x=A(i,k)*R(k,j); if(B(i,j)&lt;x) B(i,j)=x; end end end end elseif(model==3) %加权平均型 for(i=1:m) for(j=1:n) B(i,j)=0; for(k=1:s1) B(i,j)=B(i,j)+A(i,k)*R(k,j); end end end elseif(model==4) %取小上界和型 for(i=1:m) for(j=1:n) B(i,j)=0; for(k=1:s1) x=0; x=min(A(i,k),R(k,j)); B(i,j)=B(i,j)+x; end B(i,j)=min(B(i,j),1); end end elseif(model==5) %均衡平均型 C=[]; C=sum(R); for(j=1:n) for(i=1:s2) R(i,j)=R(i,j)/C(j); end end for(i=1:m) for(j=1:n) B(i,j)=0; for(k=1:s1) x=0; x=min(A(i,k),R(k,j)); B(i,j)=B(i,j)+x; end end end else disp(&#x27;模型赋值不当&#x27;); end endend","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"模糊综合评价法","slug":"模糊综合评价法","permalink":"http://chiang97912.github.io/tags/%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%B3%95/"}]},{"title":"数学建模笔记","slug":"数学建模笔记","date":"2018-08-29T02:08:05.000Z","updated":"2025-12-13T12:17:31.728Z","comments":true,"path":"2018/08/29/数学建模笔记/","permalink":"http://chiang97912.github.io/2018/08/29/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AC%94%E8%AE%B0/","excerpt":"优化模型 优化模型就是给定一个目标函数，然后在约束条件下求出该目标函数的最优值。","text":"优化模型 优化模型就是给定一个目标函数，然后在约束条件下求出该目标函数的最优值。 形如： $$ \\min(或\\max)\\ z=f(x), x=(x_1,…)\\ s.t. g_i(x)\\leq0,i=1,2,… $$ 决策变量： x 目标函数： f(x) 约束条件： $ s.t. g_i(x)\\leq0 $ 优化问题三要素： 决策变量 目标函数 约束条件 数学规划： 线性规划（Linear Programming，简称LP） 非线性规划(Nonlinear Programming，简称NLP) 整数规划 LINGO软件求解优化模型 例题： $$ \\begin{array}{lcl} \\max \\ S\\ \\begin{cases} a_i x_i=S,i=1,2,… \\ \\sum^6_{i=1}x_i=5000, \\ a_5x_6=5000. \\end{cases} \\end{array} $$ 存期年限 1年 2年 3年 4年 5年 最有收益 1.018 1.0432 1.0776 1.09715968 1.144 LINGO代码： 1234567891011!求解规划问题;model:min = S;1.018 * x1 = S;1.0432 * x2 = S;1.07776 * x3 = S;1.09715968 * x4 = S;1.144 * x5 = S;x1 + x2 + x3 + x4 + x5 + x6 = 5000;1.144 * x6 = 5000;end 运行结果： 123456789101112131415161718192021222324Global optimal solution found.Objective value: 135.2227Infeasibilities: 0.000000Total solver iterations: 0 Variable Value Reduced Cost S 135.2227 0.000000 X1 132.8317 0.000000 X2 129.6230 0.000000 X3 125.4664 0.000000 X4 123.2479 0.000000 X5 118.2016 0.000000 X6 4370.629 0.000000 Row Slack or Surplus Dual Price 1 135.2227 -1.000000 2 0.000000 0.2110548 3 0.000000 0.2059565 4 0.000000 0.1993522 5 0.000000 0.1958273 6 0.000000 0.1878093 7 0.000000 -0.2148538 8 0.000000 0.1878093 其中Objective value项即为所求目标值，下面的Variable即为在最优状态下各变量值。 关于LINGO教程网上有很多，在这里不再赘述。读者可以前往 这里查看。 MATLAB软件求解优化模型 常用的优化功能函数： 求解线性规划问题的主要函数是linprog。 求解二次规划问题的主要函数是quadprog。 求解无约束非线性规划问题的主要函数是fminbnd、fminunc和fminsearch。 求解约束非线性规划问题的主要函数是fgoalattain和fminimax。 一般步骤： 针对具体工程问题建立优化设计的数学模型 建立目标函数文件 建立约束函数文件 建立调用优化工具函数的命令文件 将优化设计的命令文件复制到MATLAB命令窗口中进行运算求解。 线性规划问题 数学模型形式： $$ \\begin{array}{lcl} \\min f^TX \\ s.t. AX\\leq b~~~~(线性不等式约束条件) \\ AeqX=beq~~~~（线性等式约束条件 \\ lb \\leq X \\leq ub~~~~(边界约束条件) \\end{array} $$ MATLAB中函数调用格式: 1[xopt, fopt]=linprog(f, A, b, Aeq, beq, lb, ub, x0, options) 参数及返回值释义： xopt: 最优解 fopt: 最优值 f: 目标函数各维变量系数向量 x0：初始点 options: 可选项 注： A, b, Aeq, beq, lb, ub均和上述数学模型对应。 二次规划问题 数学模型形式： $$ \\begin{array}{lcl} \\min f(X)=\\frac{1}{2}X^THX+C^TX \\ s.t. AX\\leq b AeqX=beq \\ lb \\leq X \\leq ub \\end{array} $$ 1[xopt, fopt]=quadprog(H,C, A, b, Aeq, beq, lb, ub, x0, options) 参数及返回值释义： xopt: 最优解 fopt: 最优值 H: 目标函数的海塞矩阵 C： 目标函数的一次项系数向量 其余同上。 示例： 求解约束优化问题 $$ \\begin{array}{lcl} f(X)=2X^2_1+2x^2_2+x^2_3-2x_1x_2+x_3\\ s.t. g(X)=x_1+3x_2+2x_3\\leq 6\\ h(X)=2x_1-x_2+x_3=4\\ x_1,x_2,x_3\\geq 0 \\end{array} $$ 解：(1)将目标函数写成二次函数的形式$f(X)=\\frac{1}{2}X^THX+C^TX$,其中： $\\begin{array}{lcl} X=\\begin{bmatrix} x_1\\ x_2\\ x_3 \\end{bmatrix} H=\\begin{bmatrix} 4 &amp; -2 &amp; 0\\ -2 &amp; 4 &amp; 0\\ 0 &amp; 0 &amp; 2 \\end{bmatrix} C=\\begin{bmatrix} 0\\ 0\\ 1 \\end{bmatrix} \\end{array}$ (2)编写求解二次规划的M文件： 12345678H=[4,-2,0;-2,4,0;0,0,2];C=[0,0,1];A=[1,3,2];b=[6];Aeq=[2,-1,1];beq=[4];lb=zeros(3,1);[xopt,fopt]=quadprig(H,C,A,b,Aeq,beq,lb) 其他规划问题 其他规划问题的MATLAB函数使用方法和前面两个类似，这里不再赘述，具体使用方法读者可以查阅相关资料。 微分方程及数值解 数学建模中的微分方程模型，其实就是高等数学中的微积分知识在建模中的应用。常见的微分方程模型有人口模型和种群数量模型。 实例 温度冷却 由物理学知道,物体冷却的速度与当时的物体温度和周围环境温度之差成正比.今 100℃的沸水注入杯里,放在室温为 20℃的环境冷却,5min 后测得水温为 60℃.求水温 u 与时间 t 的函数关系. 问题分析及模型的建立 设比例系数为k(k&gt;0),根据题意可得微分方程 $$ \\begin{array}{lcl} \\frac{du}{dt}=-k(u-20)\\ u|{t=0}=100,u|{t=5}=60 \\end{array} $$ 模型的求解 此为简单的一阶可分离变量微分方程,可得解析解$u=20+80(0.5)^{\\frac{t}{5}}$. 使用MATLAB求解微分方程解析解(通解或特解)： 12dsolve(&#x27;Du+k*(u-20)=0&#x27;,&#x27;u(0)=100&#x27;,&#x27;t&#x27;)%dsolve 为求常微分方程的符号解函数 运算结果为： 1u =20+80*exp(-k*t) 使用MATLAB求解微分方程数值解： 由给定条件$u|_{t=5}=60$,可得$k=\\frac{\\ln 2}{5}$,即$u=20+80(0.5)^\\frac{t}{5}$. MATLAB代码： 12345f=inline(&#x27;-0.2*log(2)*(u-20)&#x27;,&#x27;t&#x27;,&#x27;u&#x27;);[t,u]=ode45(f,[0,100],100);%ode45 为龙格库塔法求微分方程的数值解plot(t,u)%绘制 0 到 100 分钟的温度随时间变化的图形 MATLAB求解的函数微分方程(组) 那些不可以用积分方法求解的微分方程初值问题，可以用 MATLAB 的函数，如二三阶龙格-库塔法ode23 或四五阶龙格-库塔法 ode45 命令来求其数值解． 对于微分方程(组)的初值问题 $$ \\begin{array}{lcl} x(t)=f(t,x),x=(x_1,…,x_n)^T,f=(f_1,…,f_n)^T\\ x(t_0)=x_0, x_0(x_{01},…,x_{0n})^T \\end{array} $$ 可用下面的 MATLAB 命令实现计算： 12[t,x]= =ode23(odefun ，ts ，x0 ，options)[t,x]= =ode45(odefun ，ts ，x0 ，options) 这里 ode23 用的是 3 级 2 阶的龙格-库塔法公式，ode45 用的是 5 级 4 阶的龙格-库塔公式．输入参数 odefun 是待解方程写成的函数 M 文件或inline 格式的函数$f(t,x)$。 ts=[t0，t1，…，tf]，则输出为在指定时刻 t0，t1，…，tf 的函数值．如果输入 t0∶k∶tf，则输出为在[t0，tf]内以 k 为间隔的等分点处的函数值。 x0 为函数初值( n 维向量)。 options 可用于设定误差限（options 默认时设定相对误差${10}^{-3}$绝对误差${10}^{-6}$)，命令为： options=odeset(‘reltol’，rt，‘abstol’，at) 这里 rt，at 分别为设定的相对误差和绝对误差。 命令的输出 t 为由输入指定的 ts，x 为相应的函数值( n维向量)。 其他MATLAB函数 MATLAB中还有诸如求解偏微分方程的函数，读者可以自行查询相关资料。 机器学习 由于机器学习内容很多这里我只将常用学习算法进行归类。机器学习分为监督学习和无监督学习。其中监督学习又分为分类、集成学习、降维。 分类： K最近邻 决策树 贝叶斯分类器 逻辑回归 支持向量机 集成学习： bagging：随机森林 boosting：AdaBoost、GBDT、XGBoost（工业级） 无监督学习： K-Means DBSCAN（基于密度的聚类） 概率统计模型 $$ \\begin{array}{lcl} 聚类~~\\begin{cases} K-Means聚类（快速聚类）\\ 分层聚类（系统聚类）hierarchical\\ cluster \\end{cases}\\ 判别分析~~\\begin{cases} 根据距离判别\\ fisher判别法\\ 逐步判别法（选择变量） \\end{cases}\\ 时间序列分析~~\\begin{cases} 指数平滑\\ Box-Jenkins方法 \\end{cases} \\end{array} $$ 注：聚类分析对类及类的数量是未知的，而判别分析是已知的。 评价模型 常用评价模型： 层次分析法：定性与定量相结合的多准则决策 灰色综合评价法：灰色关联度分析 模糊综合评价法： 根据模糊数学的隶属度评价 BP神经网络综合评价法 数据包络（DEA）： 是一个对多投入/多产出的多决策单元的效率评价方法，广泛使用于业绩评价 综合评价模型： 线性加权综合法 $y=\\sum^m_{j=1}w_ix_j$ 非线性加权综合法 $y=\\prod^m_{j=1}x_j^{w_j}$ 逼近理想点（TOPSIS）方法 动态加权 动态加权函数： 分段变幂函数 偏大型正态分布函数 S型分布函数 智能计算方法 模拟退火算法（SA）：寻找全局最优思想 自动转换: 满足条件自动转换到另外一种状态 概率转换： 当不满足条件时按照一定的概率转换到另外一种状态 遗传算法（GA）： 1. 选择 2. 交叉 3. 变异 粒子群算法（PSO）：信息共享思想","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}]},{"title":"灰色关联分析模型及其改进","slug":"灰色关联分析模型及其改进","date":"2018-08-28T13:48:03.000Z","updated":"2025-12-13T12:18:52.036Z","comments":true,"path":"2018/08/28/灰色关联分析模型及其改进/","permalink":"http://chiang97912.github.io/2018/08/28/%E7%81%B0%E8%89%B2%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E6%94%B9%E8%BF%9B/","excerpt":"灰色关联分析基本原理 对于两个系统之间的因素，其随时间或不同对象而变化的关联性大小的度量，称为关联度。而根据因素之间发展趋势的相似或相异程度作为衡量因素间关联程度的方法称为灰色关联分析方法。对于本题衡量客户接受的程度与哪些因素关联度更高，我们可以使用灰色关联分析来衡量购买价格、维护成本、车门数、人员携带能力、行李箱大小、汽车安全性能等调查项和汽车可接受性之间的关联程度。","text":"灰色关联分析基本原理 对于两个系统之间的因素，其随时间或不同对象而变化的关联性大小的度量，称为关联度。而根据因素之间发展趋势的相似或相异程度作为衡量因素间关联程度的方法称为灰色关联分析方法。对于本题衡量客户接受的程度与哪些因素关联度更高，我们可以使用灰色关联分析来衡量购买价格、维护成本、车门数、人员携带能力、行李箱大小、汽车安全性能等调查项和汽车可接受性之间的关联程度。 首先，我们定义数据矩阵的最后一列l为标准要素，其余各列为需要比较的要素，分别用x‘l和x’i表示。 第一步：数据标准化 $$ X_i^\\prime=\\frac{X_i-\\min X_i}{\\max X_i-\\min X_i}=(x_i^\\prime(1),x_i^\\prime(2),x_i^\\prime(3),x_i^\\prime(4)…) $$ 第二步：求差序列 $$ \\Delta_i(k)=|x_l^\\prime-x_i^\\prime|;i=1,2,3,4… $$ 第三步：求两极差 $$ M=\\max_i \\max_k \\Delta_i(k) \\ m=\\min_i \\min_k \\Delta_i(k) $$ 第四步：计算关联系数 $$ \\gamma_{li}=\\frac{m+\\rho M}{\\Delta_i(k)+\\rho M},i=2,3,4… $$ 第五步：求灰色关联度 $$ \\gamma_{ln}=\\frac{1}{N}\\sum^N_{k=1}\\gamma_{ln}(k),i=1,2,3,4… $$ 灰色关联分析改进模型 灰色关联分析的核心是计算关联度，但是原始的关联度计算方法对各样本平等看待，即采用平权处理。但是由于各个特征对结果的影响程度是不同的，如果采用平权处理，必然会丧失数据中隐藏的潜在特征，所以本文中我们对各特征进行加权处理。此处我们采用基于距离分析法对灰色关联分析算法进行改进。 改进后的公式为: $$ \\gamma_{ln}=\\sum^N_{k=1}\\alpha(k)\\gamma_{ln}(k),i=1,2,3,4… $$ 其中权重α的计算方法如下： 我们以最优要素和最劣要素为参考要素。计算各个要素与参考要素的距离，离最优要素点近并且离最劣样本远的样本为总体较好的要素。 设数据为m x n矩阵 $$ \\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n} \\ \\vdots &amp; \\ddots &amp; \\vdots \\ a_{m1} &amp; \\cdots &amp; a_{mn} \\end{bmatrix} $$ 第一步：确定最优要素和最劣要素 $$ A^+=(a^+_1,a^+2,…,a^+n)^T \\ A^-=(a^-1,a^-2,…,a^-n)^T $$ 其中， $$ \\begin{array}{lcl} a^+l=\\max(a{1l},a{2l},…,a{ml})\\ a^-l=\\max(a{1l},a{2l},…,a{ml}), l=1,2,3,…n \\end{array} $$ 第二步：计算各要素点到参考要素点的距离。这里采用欧式距离， $$ D^+k=\\sqrt{\\sum^n{l=1}{(a{kl}-a^+_l)}^2} $$ 第三步：综合正负向距离 $$ S_k=\\frac{D^-_k}{D^+_k},k=1,2,…,m. $$ 通过上式对各要素的距离进行综合评价，即当要素与最优要素点之间的距离越小，与最劣要素点之间的距离越大，那么该要素得到的分数越高。 但是为了防止Sk的分子和分母出现零，我们将Sk的分子和分母同时加上一个偏置β（这里的β一般取1）。得到， $$ S_k=\\frac{D^-_k+\\beta}{D^+k+\\beta},k=1,2,…,m. $$ 第四步：数据归一化 $$ \\alpha_k=\\frac{S_k}{\\sum^m{k=1}S_k} $$ 则 $$ \\alpha=(\\alpha_1,\\alpha_2,…,\\alpha_m)^T $$ 即为所有权重向量。","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"灰色关联分析","slug":"灰色关联分析","permalink":"http://chiang97912.github.io/tags/%E7%81%B0%E8%89%B2%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"}]},{"title":"Tensorflow中矩阵乘法matmul和multiply详解","slug":"tensorflow中矩阵乘法matmul和multiply详解","date":"2018-04-09T12:01:13.000Z","updated":"2025-12-13T12:14:18.411Z","comments":true,"path":"2018/04/09/tensorflow中矩阵乘法matmul和multiply详解/","permalink":"http://chiang97912.github.io/2018/04/09/tensorflow%E4%B8%AD%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95matmul%E5%92%8Cmultiply%E8%AF%A6%E8%A7%A3/","excerpt":"在机器学习或者神经网络编程过程中，我们的运算对象通常是矩阵，而常用的矩阵操作就是点乘(dot product)和元素相乘(elementwise multiplication)。学过线性代数的读者肯定对点乘不会陌生，但是元素相乘就不一定知道了。其实elementwise multiplication就是将两个shape一样的矩阵按照对应元素相乘。","text":"在机器学习或者神经网络编程过程中，我们的运算对象通常是矩阵，而常用的矩阵操作就是点乘(dot product)和元素相乘(elementwise multiplication)。学过线性代数的读者肯定对点乘不会陌生，但是元素相乘就不一定知道了。其实elementwise multiplication就是将两个shape一样的矩阵按照对应元素相乘。 点乘matmul 在tensorflow中的点乘使用matmul方法，其中matmul分两种情况。 首先我们通过一个例子来了解matmul方法的使用 ： 代码示例: 12345678910111213141516171819202122import numpy as npimport tensorflow as tf&quot;&quot;&quot; 2-D &quot;&quot;&quot;print(&quot;2-D:&quot;)sess = tf.Session()a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) # 2-D tensor `a`print(&quot;a = &quot;, sess.run(a))b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) # 2-D tensor `b`print(&quot;b = &quot;, sess.run(a))c = tf.matmul(a, b)print(&quot;c = &quot;, sess.run(c))&quot;&quot;&quot; 3-D &quot;&quot;&quot;print(&quot;3-D:&quot;)a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3]) # 3-D tensor `a`print(&quot;a = &quot;, sess.run(a))b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2]) # 3-D tensor `b`print(&quot;b = &quot;, sess.run(a))c = tf.matmul(a, b)print(&quot;c = &quot;, sess.run(c))sess.close() 运行结果： 1234567891011121314151617181920212-D:a = [[1 2 3] [4 5 6]]b = [[1 2 3] [4 5 6]]c = [[ 58 64] [139 154]]3-D:a = [[[ 1 2 3] [ 4 5 6]] [[ 7 8 9] [10 11 12]]]b = [[[ 1 2 3] [ 4 5 6]] [[ 7 8 9] [10 11 12]]]c = [[[ 94 100] [229 244]] [[508 532] [697 730]]] 如果做点乘的两个矩阵的shape维度为2维，那么就按照一般矩阵点乘来计算。 如果点乘的两个矩阵的shape维度为3维，那么我们通常将第一维定义为batch_size，那么matmul方法就会逐个数据的将对应的维度按照第一种情况对两个矩阵做点乘。 元素相乘multiply 两个矩阵中对应元素各自相乘 例如有矩阵 M1 = [ a b c e f g h i j ] 和 M2 = [ k l m n o p q r s ] 那么multiply(M1,M2)的结果为： [ a*k b*l c*m e*n f*o g*p h*q i*r j*s ] 代码示例： 12345678import tensorflow as tfa = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])b = tf.constant([[10., 11., 12.], [13., 14., 15.], [16., 17., 18.]])c = tf.multiply(a, b)sess = tf.Session()print(sess.run(c))sess.close() 运行结果： 123[[ 10. 22. 36.] [ 52. 70. 90.] [112. 136. 162.]]","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/categories/tensorflow/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/tags/tensorflow/"}]},{"title":"Python爬虫入门实践","slug":"Python爬虫入门实践","date":"2018-01-23T15:55:18.000Z","updated":"2025-12-13T12:15:23.488Z","comments":true,"path":"2018/01/23/Python爬虫入门实践/","permalink":"http://chiang97912.github.io/2018/01/23/Python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/","excerpt":"写这篇博客，一来是整理我最近一两个月的数据抓取经验，二来是帮助新手快速入门爬虫。听到爬虫这个词很多人可能会联想到谷歌，百度，必应等搜索引擎，它们拥有强大的数据检索能力，为我们查找资料提供了极大的帮助。这些搜索引擎之所以强大就是因为它们有一个强大的数据抓取系统。下面我们从0到1逐层展开讲解。","text":"写这篇博客，一来是整理我最近一两个月的数据抓取经验，二来是帮助新手快速入门爬虫。听到爬虫这个词很多人可能会联想到谷歌，百度，必应等搜索引擎，它们拥有强大的数据检索能力，为我们查找资料提供了极大的帮助。这些搜索引擎之所以强大就是因为它们有一个强大的数据抓取系统。下面我们从0到1逐层展开讲解。 基础 其实爬虫很简单，归结起来就是下面两个步骤： 获取网页源代码 解析源代码获取需要的信息 获取网页源代码 在Python3中，获取网页源代码通常有两种方式：第一种是通过Python3自带的urllib库中的request.urlopen函数来请求网页源代码；第二种方式也是最常使用的方式就是使用requests库来实现网页的抓取。 urllib 首先我先来简单的介绍一下urllib库请求网页的方法： from urllib.request import urlopen response = urlopen('https://pixabay.com/en/') #抓取全球著名免费矢量图网站pixabay html = response.read() requests 下面开始介绍本教程获取网页源代码主要使用的工具：requests requests的使用很简单和urllib类似： import requests response = requests.get('https://pixabay.com/en/') #注意一定要加上url前面的安全协议https或者http不然系统会报错。 response.encoding = 'utf-8' #设置网页的源代码编码格式为utf-8，你可以根据具体情况设置诸如gbk（国标）等编码格式。 html = response.text #获取源代码 解析HTML 关于HTML我简要的说明一下：对于整个网页来说，它是使用html标记语言编写的，所以网页中的每一个元素都是一个节点，其中html标签用于包裹整个网页，head标签用于一些不需要可视化的代码编写其中包括网页的标题，引用的css文件和js文件等。而网站的主体被body标签包裹。body标签中有图层标签div（主要的标签）、img标签（图片标签）等。而每个标签都有一些属性比如class(类)、id(编号)等。其中id在整个网页中是唯一指定的，而class属性并不唯一。我们可以通过标签的层次关系以及这些标签的属性来定位我们需要抓取的数据。学习网络爬虫需要掌握一定的网页知识，如果读者欠缺这方面的知识可以前往菜鸟教程学习有关html以及css有关的知识。 解析HTML或者XML的工具或框架有很多，最常用的有: BeautifulSoup：使用正则表达式编写的html解析库 lxml：通过xml的节点查找信息的网页解析库（速度很快） scrapy：集成爬虫框架 pyquery：Python中对jquery的实现，对于熟悉前端的人来说非常容易上手。 BeautifulSoup BeautifulSoup有多种使用方法，对于查找元素可以使用find_all方法，但是笔者习惯使用select方法（css选择器语法）搜索文档。关于css选择器如果读者对前端足够熟悉的话应该能够轻松上手。经常使用到的标签包括div、span、ul、li、img、a等。我们使用点（.）表示标签的class属性，使用井（#）表示标签的id属性。在使用select方法的时候可以通过他们定位标签数据的位置。关于BeautifulSoup的具体使用方法，读者可以前往官方文档学习。 这里我们以抓取pixabay网站首页图片的url为例： 对于爬虫我建议大家使用chrome浏览器的控制台对页面进行分析（F12调出控制台）。 打开控制台后，选中Elements选项卡我们可以查看网页源代码，通过对网页的分析我们会发现图片的url为img标签的src属性，而img标签的父标签为a,a标签的父标签为div标签，div的父标签为带有class属性为flex_grid和credits的div标签，而该标签的父标签是id属性为gallery的标签。由于id属性是唯一的我们可以以该标签为源点，查找目标标签。 import requests from bs4 import BeautifulSoup response = requests.get('https://pixabay.com/en/') #请求pixabay网站 response.encoding = 'utf-8' #设置utf-8编码 html = response.text #网页源代码 soup = BeautifulSoup(html, 'lxml') #使用BeautifulSoup解析网页 imgs = soup.select('#gallery &gt; div.flex_grid.credits &gt; div &gt; a &gt; img') #使用css选择器定位链接，返回结果为包含所有图片标签的列表 for img in imgs: print(img['src']) #打印图片标签的src属性 运行结果： https://cdn.pixabay.com/photo/2018/06/23/16/22/romanesco-3493007__340.jpg https://cdn.pixabay.com/photo/2018/07/08/14/16/cat-3523992__340.jpg https://cdn.pixabay.com/photo/2018/05/30/15/31/rustic-3441673__340.jpg https://cdn.pixabay.com/photo/2016/06/29/09/28/golf-1486354__340.jpg https://cdn.pixabay.com/photo/2017/11/10/08/10/son-2935723__340.jpg https://cdn.pixabay.com/photo/2018/07/06/13/30/statue-3520416__340.jpg https://cdn.pixabay.com/photo/2018/07/08/15/32/dahlia-3524115__340.jpg https://cdn.pixabay.com/photo/2018/05/07/22/08/sydney-opera-house-3381786__340.jpg https://cdn.pixabay.com/photo/2018/07/05/23/31/ivy-3519431__340.jpg https://cdn.pixabay.com/photo/2017/06/05/14/55/glass-2374311__340.jpg https://cdn.pixabay.com/photo/2018/04/12/11/44/apple-3313225__340.jpg https://cdn.pixabay.com/photo/2017/09/22/09/48/desert-2774945__340.jpg https://cdn.pixabay.com/photo/2017/07/12/22/51/couple-2498660__340.jpg https://cdn.pixabay.com/photo/2016/06/20/03/15/pier-1467984__340.jpg https://cdn.pixabay.com/photo/2018/01/29/10/40/shower-of-sparks-3115784__340.jpg https://cdn.pixabay.com/photo/2017/09/06/20/35/massage-2722936__340.jpg https://cdn.pixabay.com/photo/2018/07/01/20/01/mercedes-3510327__340.jpg https://cdn.pixabay.com/photo/2018/06/28/15/23/soft-fruits-3504149__340.jpg https://cdn.pixabay.com/photo/2018/06/28/17/02/water-lily-3504363__340.jpg https://cdn.pixabay.com/photo/2018/06/29/01/47/piano-3505109__340.jpg lxml 总的来说使用BeautifulSoup已经能够解决大部分爬虫问题了，但是由于BeautifulSoup的另辟蹊径，独创了一套正则表达式的查询方法导致了爬虫的爬取速度非常的慢，而且BeautifulSoup对于列表项的爬取是非常的糟糕的。但是lxml就不存在着两个问题，lxml由于底层采用c语言代码编写，所以速度上是非常快的。而且由于lxml采用xpath语法解析HTML，对列表项的爬取是非常轻松的。 关于lxml框架和xpath语法，读者可以参看崔庆才的博客。 下面使用lxml爬取pixabay网站图片url: import requests from lxml import etree # 获取网页的源代码 response = requests.get('https://pixabay.com/en/') response.encoding = 'utf-8' html = response.text # 解析网页 parser = etree.HTML(html) for i in range(1,21): #打印前20张图片url link = parser.xpath('//*[@id=&quot;gallery&quot;]/div[1]/div['+ str(i) +']/a/img/@src')[0] print(link) 运行结果： https://cdn.pixabay.com/photo/2018/06/23/16/22/romanesco-3493007__340.jpg https://cdn.pixabay.com/photo/2018/07/08/14/16/cat-3523992__340.jpg https://cdn.pixabay.com/photo/2018/05/30/15/31/rustic-3441673__340.jpg https://cdn.pixabay.com/photo/2016/06/29/09/28/golf-1486354__340.jpg https://cdn.pixabay.com/photo/2017/11/10/08/10/son-2935723__340.jpg https://cdn.pixabay.com/photo/2018/07/06/13/30/statue-3520416__340.jpg https://cdn.pixabay.com/photo/2018/07/08/15/32/dahlia-3524115__340.jpg https://cdn.pixabay.com/photo/2018/05/07/22/08/sydney-opera-house-3381786__340.jpg https://cdn.pixabay.com/photo/2018/07/05/23/31/ivy-3519431__340.jpg https://cdn.pixabay.com/photo/2017/06/05/14/55/glass-2374311__340.jpg https://cdn.pixabay.com/photo/2018/04/12/11/44/apple-3313225__340.jpg https://cdn.pixabay.com/photo/2017/09/22/09/48/desert-2774945__340.jpg https://cdn.pixabay.com/photo/2017/07/12/22/51/couple-2498660__340.jpg https://cdn.pixabay.com/photo/2016/06/20/03/15/pier-1467984__340.jpg https://cdn.pixabay.com/photo/2018/01/29/10/40/shower-of-sparks-3115784__340.jpg https://cdn.pixabay.com/photo/2017/09/06/20/35/massage-2722936__340.jpg https://cdn.pixabay.com/photo/2018/07/01/20/01/mercedes-3510327__340.jpg https://cdn.pixabay.com/photo/2018/06/28/15/23/soft-fruits-3504149__340.jpg https://cdn.pixabay.com/photo/2018/06/28/17/02/water-lily-3504363__340.jpg https://cdn.pixabay.com/photo/2018/06/29/01/47/piano-3505109__340.jpg 进阶 动态数据爬取 占位 百度地图数据爬取 占位 微博数据爬取实战 占位 球探网数据爬取 占位 未完待续。。。","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://chiang97912.github.io/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://chiang97912.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"开源啦！60维维基百科词向量免费放送","slug":"开源啦！60维维基百科词向量免费放送","date":"2018-01-08T04:23:34.000Z","updated":"2025-12-13T12:17:52.442Z","comments":true,"path":"2018/01/08/开源啦！60维维基百科词向量免费放送/","permalink":"http://chiang97912.github.io/2018/01/08/%E5%BC%80%E6%BA%90%E5%95%A6%EF%BC%8160%E7%BB%B4%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E8%AF%8D%E5%90%91%E9%87%8F%E5%85%8D%E8%B4%B9%E6%94%BE%E9%80%81/","excerpt":"开源啦！60维维基百科词向量免费放送","text":"开源啦！60维维基百科词向量免费放送 使用说明 在本次开源数据中共包含4个文件，分别如下： wiki.zh.text.model wiki.zh.text.model.syn1neg.npy wiki.zh.text.model.wv.syn0.npy wiki.zh.text.vector 其中我们需要使用的仅有wiki.zh.text.model、wiki.zh.text.vector其余两个是numpy自动生成的数据。如果你的需求是计算词之间的距离，可以使用gensim包具体用法如下： import gensim #导入gensim包 model = gensim.models.Word2Vec.load(&quot;wiki.zh.text.model&quot;) #加载词向量模型 result = model.most_similar(u'足球') for each in result: print each[0] , each[1] 输出结果为： 国际足球 0.556692957878 足球运动 0.530436098576 篮球 0.518306851387 国家足球队 0.516140639782 足球队 0.513238489628 足球联赛 0.500901579857 football 0.500162124634 体育 0.499264538288 足球比赛 0.488131582737 冰球 0.48725092411 说明：前面的是和“足球”最相近的词，后面是相似度 更多gensim和词向量的用法请参考相关博客 下面是连接地址：60维词向量","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"深度学习/NLP","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://chiang97912.github.io/tags/Deep-Learning/"},{"name":"NLP","slug":"NLP","permalink":"http://chiang97912.github.io/tags/NLP/"},{"name":"word embedding","slug":"word-embedding","permalink":"http://chiang97912.github.io/tags/word-embedding/"}]},{"title":"自然语言处理入门实践","slug":"自然语言处理入门实践","date":"2017-11-16T09:20:51.000Z","updated":"2025-12-13T12:16:52.857Z","comments":true,"path":"2017/11/16/自然语言处理入门实践/","permalink":"http://chiang97912.github.io/2017/11/16/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/","excerpt":"自然语言处理入门实践 人工智能领域中有两个主流方向即机器视觉（CV）和自然语言处理（NLP）。其中自然语言处理（英语：Natural Language Processing，缩写作 NLP）是人工智能和语言学领域的分支学科。自然语言处理领域主要探讨如何处理及运用自然语言。自然语言处理包括多方面和步骤，基本有认知、理解、生成等部分。下面介绍一些NLP的基础知识。","text":"自然语言处理入门实践 人工智能领域中有两个主流方向即机器视觉（CV）和自然语言处理（NLP）。其中自然语言处理（英语：Natural Language Processing，缩写作 NLP）是人工智能和语言学领域的分支学科。自然语言处理领域主要探讨如何处理及运用自然语言。自然语言处理包括多方面和步骤，基本有认知、理解、生成等部分。下面介绍一些NLP的基础知识。 分词 提到自然语言处理当然不得不提大名鼎鼎的自然语言处理工具包NLTK了。NLTK在国外很流行，它提供包括英文分词、词性标注、命名实体的识别等等自然语言处理中的基本操作。如果各位想体验NLTK你可以通过pip install nltk来安装nltk。 ​ 但是nltk只支持英文分词，如果想对中文进行切词还得另谋他法。英文分词很方便，直接按照空格分割字符串就可以切出token字串，但是汉语是没有使用空格来分割词语。所以我给大家提供了一下几种汉语分词解决方案。 使用斯坦福大学分词器+nltk包，完美解决nltk对汉语的兼容。 使用jieba分词。 使用哈工大语言技术平台的python封装包pyltp 本人经常用的是jieba分词工具和哈工大的分词器pyltp。首先jieba分词工具分词的速度非常快，这一点可谓是完胜pyltp，而且jieba分词的准确率也和pyltp非常接近。但是jieba分词工具终究只是一个分词工具。它不支持一些高级的功能比如命名实体识别，语义角色标注等。所以如果只需要分词而不需要命名实体识别那就尽量使用jieba分词，有其它需求再使用pyltp。 你可以通过pip安装jieba和pyltp，jieba的安装非常简单，使用一个pip安装就可以了。但是pyltp的安装就没那么容易了，你除了需要安装pyltp还需要下载一个数据包，这个数据包提供了分词需要的一些词典。为了下载这个数据包你需要去Pyltp在Github主页下载整个项目，然后把项目中的ltp_data文件夹存放到一个固定位置方便以后调用。另外pyltp的具体调用方法可以前往Pyltp的官网学习。jieba分词的调用方法可以直接前往它在Github主页查看。 下面我简单介绍一下jieba分词工具的使用： 代码： # coding:utf-8 import jieba text = &quot;青年一代有理想、有本领、有担当，国家就有前途，民族就有希望。&quot; tokens = jieba.lcut(text) print(tokens) 运行结果： Building prefix dict from the default dictionary ... Loading model from cache C:\\temp\\jieba.cache Loading model cost 1.020 seconds. Prefix dict has been built succesfully. ['青年一代', '有', '理想', '、', '有', '本领', '、', '有', '担当', '，', '国家', '就', '有', '前途', '，', '民族', '就', '有', '希望', '。'] 停用词 什么是停用词呢？停用词就是在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为停用词（Stop Words）。 这些停用词都是人工输入、非自动化生成的，生成后的停用词会形成一个停用词表。但是，并没有一个明确的停用词表能够适用于所有的工具。甚至有一些工具是明确地避免使用停用词来支持短语搜索的。 简单来说就是对我们处理自然语言过程中没有帮助的词汇，例如“哈哈”、“不仅”、“如果”等。这些词蕴含的信息很少，所以在NLP中我们通常会将它们从分词结果中去掉。 那么怎么获取停用词表呢？首先你可以谷歌一下，网上有很多停用词表。不过如果你想为了方便的话可以使用我提供给你的停用词表。https://pan.baidu.com/s/1o8VFnTK 说明： 停用词表每一行就是一个停用词且该停用词表即包括标点符号也包括普通停用词。 那么有怎么去除停用词呢？ 你可以通过下面代码加载停用词，其中stopwords.txt就是停用词文件。 1stopwords = [line.strip() for line in open(&#x27;stopwords.txt&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;).readlines()] TF-IDF tf-idf（英语：term frequency–inverse document frequency）是一种用于信息检索与文本挖掘的常用加权技术。tf-idf是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。tf-idf加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了tf-idf以外，互联网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜索结果中出现的顺序。 tf是term frequency的缩写，也就是词频的意思；而idf是inverse document frequency的缩写，也就是逆词频的意思。 我大概解释一下，通常一个句子中不同的词蕴含着不同的信息，且他们的重要性是不相同的。通常一个词语在一个文本中出现的次数越高说明它就越重要，反之越不重要。这是有些细心的读者就发现了，我们前面介绍的那些停用词怎么解释，例如“不仅”，它在一个句子中出现的顺序其实也不低呀，如果我们认为它很重要的话，那么就大错特错了，因为它是不包含任何信息的。所以我们此时就引入下面一个概念，也就是逆词频。通常在多个文本中，我们认为当一个词在同一篇文本中出现的次数越高那么它就越重要，可是如果它即出现在本篇文档中又在其他文档中的频次很高，那么我们就认为它不那么重要了。我们需要降低它的重要程度。 对于在某一特定文件里的词语来说，它的重要性可表示为： $$ tf_{ij}=\\frac{n_{i,j}}{\\sum_kn_{k,j}} $$ 逆向文件频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到： $$ idf_i=\\log \\frac{|D|}{|{j:t_i\\in d_j}|} $$ 最后计算综合词频和逆词频得到最终的tfidf值 $$ tfidf_{i,j}=tf_{i,j}\\times idf_i $$ Word2vec One-hot 自然语言在计算机中是以字符或者字符串形式存在的，但是作为一个基于统计的机器学习系统，我们的运算对象是数值型的数据，所以我们需要对字符型数据进行处理。 表征单词的方式是首先建立一个较大的词汇表（例如10000），然后使用one-hot的方式对每个单词进行编码。例如单词Man，Woman，King，Queen，Apple，Orange分别出现在词汇表的第5391，9853，4914，7157，456，6257的位置，则它们分别用O5391,O9853,O4914,O7157,O456,O6257表示。其中O5391表示一个维度为10000，第5391维度的值为1其余位置值全为0的向量。 one-hot表征单词的方法最大的缺点就是每个单词都是独立的、正交的，无法知道不同单词之间的相似程度。例如Apple和Orange都是水果，词性相近，但是单从one-hot编码上来看，内积为零，无法知道二者的相似性。在NLP中，我们更希望能掌握不同单词之间的相似程度。 词嵌入 为了解决One-hot向量的缺点我们可以使用特征表征（Featurized representation）的方法对每个单词进行编码。也就是使用一个特征向量表征单词，特征向量的每个元素都是对该单词某一特征的量化描述，量化范围可以是[-1,1]之间。特征表征的例子如下图所示： Man(5391) Woman(9853) King(4914) Queen(7157) Apple(456) Orange(6257) Gender -1 1 -0.95 0.97 0.00 0.01 Royal 0.01 0.02 0.93 0.95 -0.01 0.00 Age 0.03 0.02 0.7 0.65 0.03 -0.02 Food 0.09 0.01 0.02 0.01 0.95 0.97 … … … … … … … 特征向量的长度依情况而定，特征元素越多则对单词表征得越全面。这里的特征向量长度设定为300。使用特征表征之后，词汇表中的每个单词都可以使用对应的300 x 1的向量来表示，该向量的每个元素表示该单词对应的某个特征值。每个单词用e+词汇表索引的方式标记，例如e5391, e9853, e4914, e7157, e456, e6257。 特征表征的优点是根据特征向量能清晰知道不同单词之间的相似程度，例如Apple和Orange之间的相似度较高，很可能属于同一类别。这种单词“类别”化的方式，大大提高了有限词汇量的泛化能力。这种特征化单词的操作被称为Word Embeddings，即单词嵌入。 这里特征向量的每个特征元素含义是具体的，对应到实际特征，例如性别、年龄等。而在实际应用中，特征向量很多特征元素并不一定对应到有物理意义的特征，是比较抽象的。但是，这并不影响对每个单词的有效表征，同样能比较不同单词之间的相似性。 学习词嵌入 我们可以通过构建自然语言模型（神经网络），运用梯度下降算法得到embedding。举个简单的例子，输入样本是下面这句话： I want a glass of orange ——. 通过这句话的前6个单词，预测最后的单词“juice”。 为了让神经网络输入层数目固定，可以选择只取预测单词的前4个单词作为输入，例如该句中只选择“a glass of orange”四个单词作为输入。当然，这里的4是超参数，可调。 一般地，我们把输入叫做context，输出叫做target。对应到上面这句话里： context: a glass of orange target: juice 关于context的选择有多种方法： target前n个单词或后n个单词，n可调 target前1个单词 target附近某1个单词（Skip-Gram） 关于context和target的选择，比较流行的模型有Skip-Gram和Cbow。 情感分析 pass 机器翻译 pass Attention机制 pass","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"深度学习/NLP","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://chiang97912.github.io/tags/NLP/"}]},{"title":"二级域名指向网站子目录的配置","slug":"二级域名指向网站子目录的配置","date":"2017-11-11T03:52:00.000Z","updated":"2025-12-13T12:18:13.028Z","comments":true,"path":"2017/11/11/二级域名指向网站子目录的配置/","permalink":"http://chiang97912.github.io/2017/11/11/%E4%BA%8C%E7%BA%A7%E5%9F%9F%E5%90%8D%E6%8C%87%E5%90%91%E7%BD%91%E7%AB%99%E5%AD%90%E7%9B%AE%E5%BD%95%E7%9A%84%E9%85%8D%E7%BD%AE/","excerpt":"第一步：添加二级域名 首先声明的是，我的wordpress保存在网站的根目录下的wordpress子目录，所以我现在想把wordpress目录指向二级域名blog.figurinn.xyz.经过多次尝试终于成功了。","text":"第一步：添加二级域名 首先声明的是，我的wordpress保存在网站的根目录下的wordpress子目录，所以我现在想把wordpress目录指向二级域名blog.figurinn.xyz.经过多次尝试终于成功了。 首先，你需要在你申请域名的服务商那里新增二级域名。如果你是在阿里云申请的域名，那么你需要到阿里云的DNS解析里面找到新增DNS的按钮，纪录类型选择A，然后主机纪录填你想要申请的名称，例如我的就填blog，记录值就是你服务器的IP地址，其他的默认就好了。 第二步：服务器设置 这一步你需要在你的网站根目录下增加一个名叫.htaccess的文件，然后填入一下的内容 &lt;IfModule mod_rewrite.c&gt; RewriteEngine On RewriteCond %{HTTP_HOST} ^blog.figurinn.xyz$ RewriteCond %{REQUEST_URI} !^/wordpress/ RewriteRule ^(.*)$ /wordpress/$1?Rewrite [L,QSA] &lt;/IfModule&gt; 上面的内容是根据我的网站设定的，你可以根据你的需求进行更改 如果你此时访问的二级域名不成功的话，很可能你没有开启服务器url重写功能。 如果这样，你可以按一下步骤打开服务器的url重写功能(以我的ubuntu服务器为例子) 首先确保/etc/apache2/mods-enabled/rewrite.load文件中的 LoadModule rewrite_module /usr/lib/apache2/modules/mod_ rewrite.so 没有被注释掉（如果有#号表示就被注释），如果被注释了取消注释（只需要删除前面的#）即可，然后vim保存退出。 然后编辑/etc/apache2/apache2.conf 文件，找到 &lt;Directory /var/www/&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt; 然后将AllowOverride None中的None改为All 到此为止二级域名指向服务器子目录就成功了 一些问题及解决办法 我通过blog.figurinn.xyz设置二级域名指向子目录成功后，该二级域名可以访问，可是发现当访问某一篇文章时，却发现文章的前缀还是www.figurinn.xyz/wordpress，后来发现是wordpress设置的问题 如果你也有同样的问题，你可以进入wordpress后台，然后点击设置，你会发现有“WordPress地址”、“站点地址”，如果你希望访问wordpress中某一篇文章时url的前缀也是你设置的二级域名的话，你只需要将上文提到的两个设置选项设置为你的二级域名即可。","categories":[{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"}]},{"title":"Python3连接MySQL数据库","slug":"Python3连接MySQL数据库","date":"2017-09-17T05:20:25.000Z","updated":"2025-12-13T12:15:47.754Z","comments":true,"path":"2017/09/17/Python3连接MySQL数据库/","permalink":"http://chiang97912.github.io/2017/09/17/Python3%E8%BF%9E%E6%8E%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"Python2连接数据库一般使用mysqldb库，而到了Python3已经完全不支持mysqldb库了，所以要使用其他的替代库。而Django中又使用了mysqldb库，所以我们的解决方案就是使用pymysql库来模拟mysqldb库。","text":"Python2连接数据库一般使用mysqldb库，而到了Python3已经完全不支持mysqldb库了，所以要使用其他的替代库。而Django中又使用了mysqldb库，所以我们的解决方案就是使用pymysql库来模拟mysqldb库。 先在python3中安装好pymysql库。然后在Django项目的app包的__init__.py文件中添加如下语句： import pymysql pymysql.install_as_MySQLdb() 这样我们就可以在Django项目中调用mysql数据库了。","categories":[{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/categories/%E4%BB%A3%E7%A0%81/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://chiang97912.github.io/tags/mysql/"},{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"http://chiang97912.github.io/tags/django/"},{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/tags/%E4%BB%A3%E7%A0%81/"}]},{"title":"谈谈我对于维度的理解","slug":"谈谈我对于维度的理解","date":"2017-08-25T08:14:48.000Z","updated":"2025-12-13T12:17:07.164Z","comments":true,"path":"2017/08/25/谈谈我对于维度的理解/","permalink":"http://chiang97912.github.io/2017/08/25/%E8%B0%88%E8%B0%88%E6%88%91%E5%AF%B9%E4%BA%8E%E7%BB%B4%E5%BA%A6%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"前不久和朋友聊到了维度的话题，朋友给我讲了他在一本杂志上看到的有关空间维度的文章。身处在三维空间的我们是很难理解四维空间的，我们人类理解四维空间就好比二维空间的生物理解三维空间的生物一样困难。假如蚂蚁是一种二维生物，它的活动范围只能是地面（平面），而苍蝇就是生活在三维空间的生物，它可以向上下、左右、前后中的任意一个方向移动。假设某一天苍蝇突然从空中落下停到地面休息了几秒，这时二维生物蚂蚁发现了三维生物苍蝇，但是苍蝇转瞬即逝。这种现象其实有点类似人类发现不明飞行物。我们假设外星人生活在四维空间，它可以在时间轴上任意移动，而我们人类只能从某个时间点出发并且沿着时间增大的方向匀速移动。相比于四维空间的生物能够在时间轴上以任意方向任意速度移动而言，我们三维空间的生物可能显得有点笨拙。经过这样的解释，那么经常出现在新闻版面中的不明飞行物转瞬即逝的现象就能够很好解释了。","text":"前不久和朋友聊到了维度的话题，朋友给我讲了他在一本杂志上看到的有关空间维度的文章。身处在三维空间的我们是很难理解四维空间的，我们人类理解四维空间就好比二维空间的生物理解三维空间的生物一样困难。假如蚂蚁是一种二维生物，它的活动范围只能是地面（平面），而苍蝇就是生活在三维空间的生物，它可以向上下、左右、前后中的任意一个方向移动。假设某一天苍蝇突然从空中落下停到地面休息了几秒，这时二维生物蚂蚁发现了三维生物苍蝇，但是苍蝇转瞬即逝。这种现象其实有点类似人类发现不明飞行物。我们假设外星人生活在四维空间，它可以在时间轴上任意移动，而我们人类只能从某个时间点出发并且沿着时间增大的方向匀速移动。相比于四维空间的生物能够在时间轴上以任意方向任意速度移动而言，我们三维空间的生物可能显得有点笨拙。经过这样的解释，那么经常出现在新闻版面中的不明飞行物转瞬即逝的现象就能够很好解释了。 关于维度的认知霍金曾在他的著作《时间简史》中做出过这样的理解：维度可以比喻成驾驶火车，一维世界的火车只能笔直的往前行驶，二维的火车除了可以向前行驶之外还可以转弯，而三维世界的火车除了具有以上的特质外，遇到有坡度的山还可以向上行驶。如果存在四维空间的火车，那它就可以做时间旅行了，所以我认为外星人如果存在的话应该就存在于四维空间。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://chiang97912.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"物理","slug":"物理","permalink":"http://chiang97912.github.io/tags/%E7%89%A9%E7%90%86/"},{"name":"空间维度","slug":"空间维度","permalink":"http://chiang97912.github.io/tags/%E7%A9%BA%E9%97%B4%E7%BB%B4%E5%BA%A6/"}]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://chiang97912.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"},{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/categories/python/"},{"name":"VIM","slug":"VIM","permalink":"http://chiang97912.github.io/categories/VIM/"},{"name":"深度学习","slug":"深度学习","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"深度学习/NLP","permalink":"http://chiang97912.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"},{"name":"Git","slug":"Git","permalink":"http://chiang97912.github.io/categories/Git/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/categories/tensorflow/"},{"name":"PHP","slug":"PHP","permalink":"http://chiang97912.github.io/categories/PHP/"},{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/categories/%E4%BB%A3%E7%A0%81/"},{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chiang97912.github.io/categories/%E7%88%AC%E8%99%AB/"},{"name":"随笔","slug":"随笔","permalink":"http://chiang97912.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"模型评估","slug":"模型评估","permalink":"http://chiang97912.github.io/tags/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"},{"name":"Accuracy","slug":"Accuracy","permalink":"http://chiang97912.github.io/tags/Accuracy/"},{"name":"Precision","slug":"Precision","permalink":"http://chiang97912.github.io/tags/Precision/"},{"name":"Recall","slug":"Recall","permalink":"http://chiang97912.github.io/tags/Recall/"},{"name":"F1","slug":"F1","permalink":"http://chiang97912.github.io/tags/F1/"},{"name":"ROC","slug":"ROC","permalink":"http://chiang97912.github.io/tags/ROC/"},{"name":"AUC","slug":"AUC","permalink":"http://chiang97912.github.io/tags/AUC/"},{"name":"MAP","slug":"MAP","permalink":"http://chiang97912.github.io/tags/MAP/"},{"name":"MRR","slug":"MRR","permalink":"http://chiang97912.github.io/tags/MRR/"},{"name":"NDCG","slug":"NDCG","permalink":"http://chiang97912.github.io/tags/NDCG/"},{"name":"Git","slug":"Git","permalink":"http://chiang97912.github.io/tags/Git/"},{"name":"Gogs","slug":"Gogs","permalink":"http://chiang97912.github.io/tags/Gogs/"},{"name":"Gitea","slug":"Gitea","permalink":"http://chiang97912.github.io/tags/Gitea/"},{"name":"python","slug":"python","permalink":"http://chiang97912.github.io/tags/python/"},{"name":"Pyinstaller","slug":"Pyinstaller","permalink":"http://chiang97912.github.io/tags/Pyinstaller/"},{"name":"python程序打包","slug":"python程序打包","permalink":"http://chiang97912.github.io/tags/python%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85/"},{"name":"pipenv","slug":"pipenv","permalink":"http://chiang97912.github.io/tags/pipenv/"},{"name":"virtualenv","slug":"virtualenv","permalink":"http://chiang97912.github.io/tags/virtualenv/"},{"name":"Python","slug":"Python","permalink":"http://chiang97912.github.io/tags/Python/"},{"name":"VIM","slug":"VIM","permalink":"http://chiang97912.github.io/tags/VIM/"},{"name":"C/C++","slug":"C-C","permalink":"http://chiang97912.github.io/tags/C-C/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://chiang97912.github.io/tags/tensorflow/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://chiang97912.github.io/tags/Deep-Learning/"},{"name":"NLP","slug":"NLP","permalink":"http://chiang97912.github.io/tags/NLP/"},{"name":"mysql","slug":"mysql","permalink":"http://chiang97912.github.io/tags/mysql/"},{"name":"sql","slug":"sql","permalink":"http://chiang97912.github.io/tags/sql/"},{"name":"lamp","slug":"lamp","permalink":"http://chiang97912.github.io/tags/lamp/"},{"name":"linux","slug":"linux","permalink":"http://chiang97912.github.io/tags/linux/"},{"name":"PHP","slug":"PHP","permalink":"http://chiang97912.github.io/tags/PHP/"},{"name":"算法","slug":"算法","permalink":"http://chiang97912.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数学建模","slug":"数学建模","permalink":"http://chiang97912.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"代码","slug":"代码","permalink":"http://chiang97912.github.io/tags/%E4%BB%A3%E7%A0%81/"},{"name":"模糊综合评价法","slug":"模糊综合评价法","permalink":"http://chiang97912.github.io/tags/%E6%A8%A1%E7%B3%8A%E7%BB%BC%E5%90%88%E8%AF%84%E4%BB%B7%E6%B3%95/"},{"name":"灰色关联分析","slug":"灰色关联分析","permalink":"http://chiang97912.github.io/tags/%E7%81%B0%E8%89%B2%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chiang97912.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"word embedding","slug":"word-embedding","permalink":"http://chiang97912.github.io/tags/word-embedding/"},{"name":"服务器配置","slug":"服务器配置","permalink":"http://chiang97912.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"},{"name":"django","slug":"django","permalink":"http://chiang97912.github.io/tags/django/"},{"name":"物理","slug":"物理","permalink":"http://chiang97912.github.io/tags/%E7%89%A9%E7%90%86/"},{"name":"空间维度","slug":"空间维度","permalink":"http://chiang97912.github.io/tags/%E7%A9%BA%E9%97%B4%E7%BB%B4%E5%BA%A6/"}]}