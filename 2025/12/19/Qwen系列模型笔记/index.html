<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 8.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chiang97912.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Qwen 论文：Qwen Technical Report Qwen：使用了3T token, 数据包含多样化各个领域的文本和代码。">
<meta property="og:type" content="article">
<meta property="og:title" content="Qwen系列模型笔记">
<meta property="og:url" content="http://chiang97912.github.io/2025/12/19/Qwen%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Peter&#39;s Blog">
<meta property="og:description" content="Qwen 论文：Qwen Technical Report Qwen：使用了3T token, 数据包含多样化各个领域的文本和代码。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-12-19T14:58:34.000Z">
<meta property="article:modified_time" content="2025-12-23T17:12:38.110Z">
<meta property="article:author" content="Peter Chiang">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Qwen">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://chiang97912.github.io/2025/12/19/Qwen%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Qwen系列模型笔记 | Peter's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Peter's Blog" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Peter's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chiang97912.github.io/2025/12/19/Qwen%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpeg">
      <meta itemprop="name" content="Peter Chiang">
      <meta itemprop="description" content="Stay hungry, stay foolish!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Peter's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Qwen系列模型笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-12-19 22:58:34" itemprop="dateCreated datePublished" datetime="2025-12-19T22:58:34+08:00">2025-12-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-12-24 01:12:38" itemprop="dateModified" datetime="2025-12-24T01:12:38+08:00">2025-12-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">大模型</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="qwen"><a class="markdownIt-Anchor" href="#qwen"></a> <strong>Qwen</strong></h1>
<p>论文：<a href="http://arxiv.org/abs/2309.16609">Qwen Technical Report</a></p>
<p>Qwen：使用了3T token, 数据包含多样化各个领域的文本和代码。</p>
<span id="more"></span>
<h2 id="数据"><a class="markdownIt-Anchor" href="#数据"></a> <strong>数据</strong></h2>
<ul>
<li><strong>网页数据</strong>：先从HTML中抽取文本，并用语言识别工具识别语种和内容。</li>
<li><strong>去重技术提升数据多样性</strong>：包括归一化后的精确匹配删除，以及使用MinHash、LSH算法的模糊数据删除。</li>
<li><strong>过滤低质量数据</strong>：基于规则和机器学习的方法，使用多个模型对内容进行打分（语言模型、文本质量评分模型、识别潜在攻击性或不当内容的模型等），同时也会通过人工对各种来源的文本进行采样并进行审核以确保质量。</li>
<li><strong>有选择的对某些来源的数据进行上采样</strong>：确保模型接受到各种高质量内容的训练。</li>
<li><strong>预训练加入高质量的多任务数据</strong>：研究表明，使用多任务质量数据可以增强zero-shot，few-shot能力。</li>
<li><strong>确保评估公平性</strong>：将相关训练数据从评测集中删除。（采用13-gram overlap）</li>
</ul>
<h2 id="分词器"><a class="markdownIt-Anchor" href="#分词器"></a> <strong>分词器</strong></h2>
<p>词汇表的设计显著影响模型的训练效率和下游任务的性能，Qwen采用BPE分词器方法（遵循GPT-3.5和GPT-4），从开源的快速BPE Tokenizer, tiktoken开始，并选择词汇表cl100l为基础作为起点，用常用汉字、短语以及其他语言的单词来增加词汇量以便增强多语言的性能（这里特别说明对中文词汇进行了增加），最终词汇表的大小为152K。</p>
<h2 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> <strong>模型结构</strong></h2>
<p>Qwen是使用Transformer的修改版本设计的，具体来说，是采用了LlaMA的架构设计，Qwen对架构的修改包括以下几个方面：</p>
<ul>
<li>嵌入层和输出映射（Embedding and output projection）：根据初步的实验结果，选择了不受限嵌入方法，而不是捆绑输入嵌入和输出投影的权重。</li>
<li>位置编码（Positional embedding）：选择<strong>RoPE</strong>作为将位置信息纳入模型的首选。Qwen选择使用 FP32 精度作为逆频率矩阵，而不是 BF16 或 FP16，以便优先考虑模型性能并实现更高的精度。</li>
<li>偏置（Bias）：在 QKV 注意力层中添加偏置以增强模型的外推能力。</li>
<li>归一化（Pre-Norm &amp; RMSNorm）：文中提到现代Transformer模型广泛使用前置归一化(<strong>Pre-Norm</strong>)，得益于Pre-Norm使得训练更加稳定（更容易训练），最新的研究也提出了一些提高训练稳定性的替代方法（计划在未来Qwen系列模型中进行探索），Qwen已将传统归一化方法替换为<strong>RMSNorm（<strong>RMSNorm是LayerNorm的一个变体</strong>）</strong>，在相同的性能下提高了效率。
<ul>
<li>归一化方法参考：<a href="/2025/12/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BD%92%E4%B8%80%E5%8C%96%E6%96%B9%E6%B3%95/" title="大模型归一化方法">大模型归一化方法</a></li>
<li>Pre-Norm和Post-Norm：</li>
</ul>
</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Pre Norm：</mtext><msub><mi mathvariant="bold-italic">x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi mathvariant="bold-italic">x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>F</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold-italic">x</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>Post Norm</mtext><mo>:</mo><msub><mi mathvariant="bold-italic">x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="normal">Norm</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold-italic">x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>F</mi><mi>t</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold-italic">x</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Pre Norm}： \boldsymbol{x}_{t+1}=\boldsymbol{x}_{t}+F_{t} ( \mathrm{N o r m} ( \boldsymbol{x}_{t} ) ) \\
\text{Post Norm}:  \boldsymbol{x}_{t+1}=\operatorname{N o r m} ( \boldsymbol{x}_{t}+F_{t} ( \boldsymbol{x}_{t} ) )
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord text"><span class="mord">Pre Norm</span></span><span class="mord cjk_fallback">：</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Post Norm</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.652771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>激活函数（Activation function）：采用SwiGLU作为激活函数，它是Swish和门控线性单元的组合。初步实验验证，基于GLU的激活函数效果优于基于其他基线的选项，比如GeLU研究中的常见做法，将FFN的维度从隐藏层大小的4倍减少为8/3倍。
<ul>
<li>激活函数：<a href="/2025/12/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" title="大模型激活函数">大模型激活函数</a></li>
</ul>
</li>
</ul>
<h2 id="扩展上下文"><a class="markdownIt-Anchor" href="#扩展上下文"></a> <strong>扩展上下文</strong></h2>
<p>Qwen实现了简单的免于训练的技术可以在预测阶段扩展上下文长度。关键技术之一是<strong>NTK感知插值</strong>，不同于位置插值（PI）需要对RoPE的每个维度进行均等缩放，<strong>NTK感知插值调整RoPE基数防止在免训练模式下高频信息丢失</strong>。进一步提升性能，实现<strong>动态NTK-感知插值</strong>，按照块动态改变规模，以避免严重的性能下降，这些技术可以有效扩展Transformer模型的上下文长度，且不损害计算效率和准确性。</p>
<h1 id="qwen2"><a class="markdownIt-Anchor" href="#qwen2"></a> <strong>Qwen2</strong></h1>
<p>论文：<a href="http://arxiv.org/abs/2407.10671">Qwen2 Technical Report</a></p>
<p>源码：<a href="https://github.com/huggingface/transformers/tree/v4.39.3/src/transformers/models/qwen2">https://github.com/huggingface/transformers/tree/v4.39.3/src/transformers/models/qwen2</a></p>
<h2 id="模型结构-2"><a class="markdownIt-Anchor" href="#模型结构-2"></a> <strong>模型结构</strong></h2>
<p>模型结构基于Transformer实现，并且包括因果掩码的自注意力机制。实现4个不同大小的DenseModel和1个MOEModel。</p>
<h3 id="qwen2-dense-model"><a class="markdownIt-Anchor" href="#qwen2-dense-model"></a> <strong>Qwen2 Dense Model</strong></h3>
<p>由多个Transformer层构成，每层包含因果注意力机制和前馈神经网络FFNs, 相比之前系列主要不同有：</p>
<ul>
<li><strong>分组查询注意力</strong>（Grouped Query Attention，GQA）：分组查询注意力(GQA)取代传统的多头注意力(MHA)。 GQA优化推理过程中的KV缓存使用，显著提高吞吐。这种机制将多个query头组合在一起，共享同一组key和value矩阵。因此需要缓存的key和value矩阵就大大减少了，节省了内存占用。同时，推理时可以对多个query一起计算attention，显著提高了计算效率。</li>
<li><strong>双块注意力结合YARN</strong>（Dual Chunk Attention with YARN）：为了扩展上下文窗口，实现双块注意力（Dual Chunk Attention, DCA）, 将长序列分割成可管理的块长度，如果输入可以在一个块中处理，DCA会产生与原始结果相同的结果注意力。DCA有利于有效捕捉块内、块间的不同Token的相对位置信息，从而提高长上下文性能。此外，还使用YARN重新调整注意力权重以获得更好的长度外推。</li>
</ul>
<p>激活函数仍然使用SwiGLU, 位置编码使用RoPE, Attention使用QKV偏置，RMSNorm前置归一化使得训练稳定。</p>
<p>双块注意力：双块注意力会把很长的输入序列切割成若干个“块”（chunk）。如果输入不太长，只需一个块就能处理，那么DCA就等同于普通的注意力机制。但如果输入很长，需要很多个块来处理时，DCA就会发挥作用。它不仅能捕捉每个块内部单词之间的关系，还能捕捉不同块之间单词的相对位置关系。</p>
<p><a href="https://arxiv.org/abs/2309.00071">YARN</a> (NTK-aware + NTK-by-parts + Dynamic NTK)：YaRN是基于NTK-aware方法的进一步拓展，通过结合<strong>温度缩放</strong>和<strong>NTK-by-parts</strong>插值技术，全面提升长文本外推能力。</p>
<p>大模型位置编码：<a href="https://zhuanlan.zhihu.com/p/15311461897">从ROPE到Yarn, 一条通用公式速通长文本大模型中的位置编码</a></p>
<p>参考文章：<a href="https://zhuanlan.zhihu.com/p/709733560">稳步前行的阿里云大模型——Qwen2凭什么蝉联榜首？</a></p>
<h3 id="qwen2-mixture-of-exports-model"><a class="markdownIt-Anchor" href="#qwen2-mixture-of-exports-model"></a> <strong>Qwen2 Mixture-of-exports Model</strong></h3>
<p>Qwen2 MOE模型架构和Qwen1.5-MoE-A2.7B的架构非常相似，MoE FFN取代FFN由n个独立的FFN构成，每个作为专家服务。每个Token都被定向到特定的专家Ei进行概率（基于门控网络G分配的概率）计算：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">p</mi><mo>=</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow><mrow><mo fence="true">(</mo><mi>G</mi><mrow><mo fence="true">(</mo><mi mathvariant="bold">x</mi><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace linebreak="newline"></mspace><mi mathvariant="bold">y</mi><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><msub><mo><mi mathvariant="normal">top</mi><mo>⁡</mo></mo><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">p</mi><mo stretchy="false">)</mo></mrow></munder><msub><mi mathvariant="bold">p</mi><mi>i</mi></msub><msub><mi>E</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{p}=\mathrm{s o f t m a x} \left( G \left( \mathbf{x} \right) \right) , \\
\mathbf{y}=\sum_{i \in\operatorname{t o p}_{k} ( \mathbf{p} )} \mathbf{p}_{i} E_{i} ( \mathbf{x} ) .
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathbf">p</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.07778em;">f</span><span class="mord mathrm">t</span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal">G</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.577118em;vertical-align:-1.527113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.808995em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mop mtight"><span class="mop mtight"><span class="mord mathrm mtight">t</span><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">p</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23015999999999992em;"><span style="top:-2.2341314285714287em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.26586857142857145em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathbf mtight">p</span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.527113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">p</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></p>
<p>参考文章：<a href="https://zhuanlan.zhihu.com/p/21021458859">https://zhuanlan.zhihu.com/p/21021458859</a></p>
<h2 id="后训练数据"><a class="markdownIt-Anchor" href="#后训练数据"></a> <strong>后训练数据</strong></h2>
<h3 id="自动数据合成"><a class="markdownIt-Anchor" href="#自动数据合成"></a> <strong>自动数据合成</strong></h3>
<p>维持大规模指令的标注响应数据的质量是具有挑战的，特别是那些需要专家、经验、仔细耐心标注的数据。应对这些挑战，我们设计了各种自动对齐策略来大规模合成数据。</p>
<ul>
<li><strong>拒绝采样</strong>：对于具有明确最终答案的数学或类似任务，应用拒绝采样提高质量。LLM的任务是为每条质量生成多个响应，即推理路径。那些可以导向正确结果切被模型认为是合理的路径会被保留，作为示例数据。通过相对正确和相对错误路径生成偏好数据。</li>
<li><strong>执行反馈</strong>：对于代码类的任务，用LLM生成解决方案和相关测试用例。评估这些解决方案的方法是编译和执行测试用例，据此构建示例和偏好数据。这个方法也被应用于评估指令遵循的能力，对于每条具有约束的指令，比如长度限制等，用LLM生成Python校验方法确保结果是否跟指令对齐。</li>
<li><strong>数据再利用</strong>：创建有技巧性的文学类写作任务对于没有经过专业训练的标注人员是有挑战的。为处理这类问题，我们从公开领域收集了高质量的文学作品以及使用LLM开发不同程度的细节指令，这些指令和原始作品一起作为示例数据。例如，要编译生动引人入胜的角色扮演响应，我们从维基百科等知识库中获取详细的角色简介，指导大模型生成相应指令和响应。这个过程，类似做阅读理解任务，维持确保角色个人信息的完整性。</li>
<li><strong>宪法反馈</strong>：宪法AI是指引导大模型生成预先定义准则的响应的过程。为确保例如安全性和价值观的遵守，编制了宪法数据集。该数据集描述需要被遵循和被规避的准则。它被用来指导大模型生产对齐响应和背离响应，从而制作示例和偏好数据。</li>
</ul>
<p>拒绝采样：拒绝采样的核心思想是让模型生成多个答案，然后只选择最优的答案来继续训练。</p>
<p>参考文章：<a href="https://juejin.cn/post/7413669480659025930">模型结构-qwen2</a></p>

    </div>

    
    
    
        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"># 大模型</a>
              <a href="/tags/LLM/" rel="tag"># LLM</a>
              <a href="/tags/Qwen/" rel="tag"># Qwen</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/12/16/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/" rel="prev" title="混合专家模型笔记">
      <i class="fa fa-chevron-left"></i> 混合专家模型笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/12/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BD%92%E4%B8%80%E5%8C%96%E6%96%B9%E6%B3%95/" rel="next" title="大模型归一化方法">
      大模型归一化方法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#qwen"><span class="nav-number">1.</span> <span class="nav-text"> Qwen</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.</span> <span class="nav-text"> 数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E8%AF%8D%E5%99%A8"><span class="nav-number">1.2.</span> <span class="nav-text"> 分词器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">1.3.</span> <span class="nav-text"> 模型结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%A9%E5%B1%95%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="nav-number">1.4.</span> <span class="nav-text"> 扩展上下文</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#qwen2"><span class="nav-number">2.</span> <span class="nav-text"> Qwen2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84-2"><span class="nav-number">2.1.</span> <span class="nav-text"> 模型结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#qwen2-dense-model"><span class="nav-number">2.1.1.</span> <span class="nav-text"> Qwen2 Dense Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#qwen2-mixture-of-exports-model"><span class="nav-number">2.1.2.</span> <span class="nav-text"> Qwen2 Mixture-of-exports Model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8E%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="nav-number">2.2.</span> <span class="nav-text"> 后训练数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%95%B0%E6%8D%AE%E5%90%88%E6%88%90"><span class="nav-number">2.2.1.</span> <span class="nav-text"> 自动数据合成</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Peter Chiang"
      src="/uploads/avatar.jpeg">
  <p class="site-author-name" itemprop="name">Peter Chiang</p>
  <div class="site-description" itemprop="description">Stay hungry, stay foolish!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Chiang97912" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chiang97912" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chiang97912@163.com" title="E-Mail → mailto:chiang97912@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/jiang-peng-51-20" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;jiang-peng-51-20" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://kexue.fm/" title="https:&#x2F;&#x2F;kexue.fm&#x2F;" rel="noopener" target="_blank">科学空间</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.bobinsun.cn/" title="https:&#x2F;&#x2F;www.bobinsun.cn&#x2F;" rel="noopener" target="_blank">阿拉灯神丁Vicky侃AI</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Peter Chiang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '867b8dcfa3b37ec0d9a7',
      clientSecret: '4d625400022d5d9a529bfcec23e675f1b33bc672',
      repo        : 'comment',
      owner       : 'Chiang97912',
      admin       : ['Chiang97912'],
      id          : 'cec45b297aa9d75947b339c3eec9b8ab',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
